<!DOCTYPE html>
<html lang="en | zh-CN | zh-TW">





<head>
  <meta charset="UTF-8">
  <link rel="apple-touch-icon" sizes="76x76" href="/img/apple-touch-icon.png">
  <link rel="icon" type="image/png" href="/img/leaf.jpeg">
  <meta name="viewport"
        content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no, shrink-to-fit=no">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <meta name="description" content="">
  <meta name="author" content="cowarder">
  <meta name="keywords" content="">
  <title>cowarder</title>

  <link rel="stylesheet" href="/lib/font-awesome/css/all.min.css"  >
<link rel="stylesheet" href="/lib/bootstrap/css/bootstrap.min.css"  >
<link rel="stylesheet" href="/lib/mdbootstrap/css/mdb.min.css"  >
<link rel="stylesheet" href="/lib/github-markdown/github-markdown.min.css"  >
<link rel="stylesheet" href="//at.alicdn.com/t/font_1067060_qzomjdt8bmp.css">


  <link rel="stylesheet" href="/lib/prettify/github-v2.min.css"  >

<link rel="stylesheet" href="/css/main.css"  >


  <link rel="stylesheet" href="/lib/fancybox/jquery.fancybox.min.css"  >


</head>


<body>
  <header style="height: 100vh;">
    <nav id="navbar" class="navbar fixed-top  navbar-expand-lg navbar-dark scrolling-navbar">
  <div class="container">
    <a class="navbar-brand"
       href="/">&nbsp;<strong>cowarder</strong>&nbsp;</a>

    <button id="navbar-toggler-btn" class="navbar-toggler" type="button" data-toggle="collapse"
            data-target="#navbarSupportedContent"
            aria-controls="navbarSupportedContent" aria-expanded="false" aria-label="Toggle navigation">
      <div class="animated-icon"><span></span><span></span><span></span></div>
    </button>

    <!-- Collapsible content -->
    <div class="collapse navbar-collapse" id="navbarSupportedContent">
      <ul class="navbar-nav ml-auto text-center">
        
          
          
          <li class="nav-item">
            <a class="nav-link" href="/">Home</a>
          </li>
        
          
          
          <li class="nav-item">
            <a class="nav-link" href="/archives/">Archives</a>
          </li>
        
          
          
          <li class="nav-item">
            <a class="nav-link" href="/tags/">Tags</a>
          </li>
        
          
          
          <li class="nav-item">
            <a class="nav-link" href="/about/">About</a>
          </li>
        
        
          <li class="nav-item" id="search-btn">
            <a class="nav-link" data-toggle="modal" data-target="#modalSearch">&nbsp;&nbsp;<i
                class="iconfont icon-search"></i>&nbsp;&nbsp;</a>
          </li>
        
      </ul>
    </div>
  </div>


</nav>

    <div class="view intro-2" id="background"
         style="background: url('/img/main_page.jpg')no-repeat center center;
           background-size: cover;
           background-attachment: fixed;">
      <div class="full-bg-img">
        <div class="mask rgba-black-light flex-center">
          <div class="container text-center white-text fadeInUp">
            <span class="h2" id="subtitle">
              
            </span>

            
          </div>

          
            <div class="scroll-down-bar">
              <i class="fas fa-angle-down scroll-down-arrow"></i>
            </div>
          
        </div>
      </div>
    </div>
  </header>

  <main>
    
      <div class="container nopadding-md">
        <div class="py-5 z-depth-3" id="board">
          
          <div class="container">
            <div class="row">
              <div class="col-12 col-md-10 m-auto">
                


  <div class="row mb-4 mx-auto">
    
    
      <div class="col-12 col-md-4 m-auto">
        <a href="/2020/02/11/cvpr2020/" target="_self">
          <img src="/img/cvpr2020.png" srcset="undefined" alt="cvpr2020" class="img-fluid rounded z-depth-3 index-thumbnails">
        </a>
      </div>
    
    <div class="col-12 col-md-8 m-auto">
      <a href="/2020/02/11/cvpr2020/">
        <p class="h4 index-header">cvpr2020</p>
        
        
          
        
        <div class="index-excerpt" >
          <div class="index-text mb-1">这篇文章主要对CVPR2020中涉及到的目标检测的文章做一个简短总结，提炼总体文章思路，以备查阅。
《Few-Shot Object Detection with Attention-RPN and Multi-Relation Detector》
小样本学习的文章。目标检测需要大量标注工作，利用少量标注样本训练模型得到更好的效果在一些任务上面更加需要。文章中主要有两点贡献，首先作者提出了一个新的网络（带有注意力机制的RPN和多关系检测器的小样本目标检测网络），在不用重新训练和微调的情况下检测新的物体，第二点贡献在于设计了一个新的数据集(FSOD)，其中包括1000个类别，每个类别只有很少的图片，利用这个数据集，模型相较于COCO数据集上面进行训练，取得了更好的效果。在few-shot learning任务中，我们一般将带有标签的图片称为support image，等待分割的图片称为query image，注意力机制RPN通过关注给定的支持类别来过滤掉其他类别的对象建议，然后多关系检测器将查询建议与支持图像进行匹配。
《Bridging the Gap Between Anchor-b</div>
        </div>
      </a>

      <div>
        
          <i class="iconfont icon-riqi2"></i>&nbsp;2020-02-11&nbsp;&nbsp;
        
        
        
          <i class="iconfont icon-tag"></i>
          
            <a href="/tags/object%20detection">object detection</a>&nbsp;
          
        
      </div>
    </div>
  </div>

  <div class="row mb-4 mx-auto">
    
    
      <div class="col-12 col-md-4 m-auto">
        <a href="/2020/01/28/mobile/" target="_self">
          <img src="/img/mobilenet.png" srcset="undefined" alt="MobileNet" class="img-fluid rounded z-depth-3 index-thumbnails">
        </a>
      </div>
    
    <div class="col-12 col-md-8 m-auto">
      <a href="/2020/01/28/mobile/">
        <p class="h4 index-header">MobileNet</p>
        
        
          
        
        <div class="index-excerpt" >
          <div class="index-text mb-1">卷积神经网络在计算机视觉领域已经得到了广泛应用，在各种视觉任务中都取得了比较好的效果。大趋势是通过不断增加网络深度、设计更加复杂的网络来提高模型精度。但是随着网络模型的增加，模型存储需要的内存以及运行需要的算力也在不断增加。在某些实际应用领域，例如嵌入式设备，这样庞大而复杂的网络是很难被应用的，一方面是模型过于庞大，面临内存不足的问题，而另外一方面，这些应用领域要求延迟低，而网络参数越多计算量越大，延迟就会越高。因此研究小而且高效的网络对工业界实际应用具有非常大的意义。
考虑到硬件设备的限制，目前在网络研究方面主要分为两个方面，一是对于训练好的模型进行压缩，减少参数量。另外一种是直接设计一个小的模型进行训练。其目标在于在保证模型精度的情况下减少参数数目，同时提升模型精度。本文所做的改进属于后者。
深度可分离卷积(depthwise seperable convolution)MobileNet中的基本组建是深度可分离卷积(depthwise seperable convolution)，首先我们需要分析一个传统的卷积操作。

 


假设我们有一个1212的输入特征图，通道数为3($D</div>
        </div>
      </a>

      <div>
        
          <i class="iconfont icon-riqi2"></i>&nbsp;2020-01-28&nbsp;&nbsp;
        
        
        
      </div>
    </div>
  </div>

  <div class="row mb-4 mx-auto">
    
    
      <div class="col-12 col-md-4 m-auto">
        <a href="/2020/01/15/activation/" target="_self">
          <img src="/img/relu.png" srcset="undefined" alt="论文阅读《Delving Deep into Rectifiers Surpassing Human-Level Performance on ImageNet Classification》" class="img-fluid rounded z-depth-3 index-thumbnails">
        </a>
      </div>
    
    <div class="col-12 col-md-8 m-auto">
      <a href="/2020/01/15/activation/">
        <p class="h4 index-header">论文阅读《Delving Deep into Rectifiers Surpassing Human-Level Performance on ImageNet Classification》</p>
        
        
          
        
        <div class="index-excerpt" >
          <div class="index-text mb-1">最近抽空看了一下何凯明2015年的文章《Delving Deep into Rectifiers: Surpassing Human-Level Performance on ImageNet Classification》，这篇文章里面主要分为两个部分，第一部分作者提出了PReLU激活函数，第二部分提出了Kaiming参数初始化方法，关于Kaiming初始化，我们已经在上一篇文章中做了推倒，这里不再赘述。PReLU方法为ReLU方法的改进版本，因此，本文不仅仅局限于这篇文章，而是借此对几种常见的激活函数进行探讨
Sigmoid函数和Tanh函数在神经网络发展初期，Sigmoid函数和Tanh函数是最常见的激活函数，它们的函数图像如下图所示：




其中蓝色的线表示Tanh函数，绿色的线表示Sigmoid函数，可以看到，Tanh激活函数实际上相当于Sigmoid函数的平移
$$Sigmoid:f(z)=\frac{1}{1+e^{-z}}$$
$$Tanh:f(z)=\frac{e^z-e^{-z}}{e^z+e^{-z}}$$
但是在研究过中发现，Sigmoid函数和Tanh函数作</div>
        </div>
      </a>

      <div>
        
          <i class="iconfont icon-riqi2"></i>&nbsp;2020-01-15&nbsp;&nbsp;
        
        
        
          <i class="iconfont icon-tag"></i>
          
            <a href="/tags/%E8%AE%BA%E6%96%87">论文</a>&nbsp;
          
        
      </div>
    </div>
  </div>

  <div class="row mb-4 mx-auto">
    
    
      <div class="col-12 col-md-4 m-auto">
        <a href="/2020/01/07/param-init/" target="_self">
          <img src="/img/kaiming.png" srcset="undefined" alt="参数初始化" class="img-fluid rounded z-depth-3 index-thumbnails">
        </a>
      </div>
    
    <div class="col-12 col-md-8 m-auto">
      <a href="/2020/01/07/param-init/">
        <p class="h4 index-header">参数初始化</p>
        
        
          
        
        <div class="index-excerpt" >
          <div class="index-text mb-1">深度学习中的网络初始化指的是在训练网络之前，对每个节点的权重和偏置进行初始化的过程，一个参数的初始化关系到网络是否能够训练出好的结果以及模型收敛的速度。本文简要介绍两种常见的参数初始化方法的推导过程及原理。
Xavier初始化神经网络做的任务无非是将原本的样本稳定映射为它的类别，也就是将样本空间映射为类别空间，如果样本空间和类别空间差距过大，例如类别空间特别稠密，样本空间特别稀疏，那么在类别空间得到的用于反向传播的误差丢给样本空间之后就会变得微不足道，反之，如果类别空间特别稀疏，样本空间特别稠密，在类别空间得到的误差丢给样本空间之后会造成爆炸性的影响，导致模型梯度爆炸，无法收敛。因此，我们需要让类别空间和样本空间之间的分布差异不要太大，也就是它们之间的方差尽可能相等，这就是Xavier初始化的出发点。
对于 y. = wx ，假设有：$$Var(Y) = Var(w_iX)=Var(w_i)*Var(X)+E^2(X)*Var(w_i)+E^2(w_i)*Var(X)\qquad(1)$$
当$X, w_i$都符合均值为0的正态分布时，$E(X),E(w_i)$均为0，公式进一步简化为</div>
        </div>
      </a>

      <div>
        
          <i class="iconfont icon-riqi2"></i>&nbsp;2020-01-07&nbsp;&nbsp;
        
        
        
          <i class="iconfont icon-tag"></i>
          
            <a href="/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0">深度学习</a>&nbsp;
          
        
      </div>
    </div>
  </div>

  <div class="row mb-4 mx-auto">
    
    
      <div class="col-12 col-md-4 m-auto">
        <a href="/2019/12/25/NMS/" target="_self">
          <img src="/img/nms.png" srcset="undefined" alt="NMS(非极大值抑制算法)" class="img-fluid rounded z-depth-3 index-thumbnails">
        </a>
      </div>
    
    <div class="col-12 col-md-8 m-auto">
      <a href="/2019/12/25/NMS/">
        <p class="h4 index-header">NMS(非极大值抑制算法)</p>
        
        
          
        
        <div class="index-excerpt" >
          <div class="index-text mb-1">什么是NMS算法？非极大值抑制NMS(Non-maximum Suppression)算法是目标检测任务中一个不可或缺的模块，目标检测的任务是输入一幅图片，利用不同大小、不同尺寸的边界框找出图片中对应的目标物体。

 


但是在实际的检测过程中，我们的检测算法往往会针对一个目标物体，框出许多边界框。

 


但是我们最终对于每个物体实例，最理想的情况下只需要保留一个最佳的边界框，这就应用到了我们的NMS算法。NMS算法通过选定一个得分(confidence score)最高的边界框，过滤掉(抑制)与其相近的其他边界框，并给出相应框对应的类别。

 


NMS算法实现

输入：边界框集合$\textbf{B}$，对应的IOU阈值$\textbf{T}$
新建一个空的集合$\textbf{D}$，用于保存最终的结果
将$\textbf{B}$中的边界框按照得分由高到低排序
选取$\textbf{B}$中得分最高的边界框$\textbf{m}$，放到$\textbf{D}$中
计算$\textbf{B}$中剩余边界框与$\textbf{m}$的IOU值，IOU大于$\textbf{T}</div>
        </div>
      </a>

      <div>
        
          <i class="iconfont icon-riqi2"></i>&nbsp;2019-12-25&nbsp;&nbsp;
        
        
        
          <i class="iconfont icon-tag"></i>
          
            <a href="/tags/object%20detection">object detection</a>&nbsp;
          
        
      </div>
    </div>
  </div>

  <div class="row mb-4 mx-auto">
    
    
      <div class="col-12 col-md-4 m-auto">
        <a href="/2019/12/10/bayes-optim/" target="_self">
          <img src="/img/bayes.png" srcset="undefined" alt="贝叶斯优化" class="img-fluid rounded z-depth-3 index-thumbnails">
        </a>
      </div>
    
    <div class="col-12 col-md-8 m-auto">
      <a href="/2019/12/10/bayes-optim/">
        <p class="h4 index-header">贝叶斯优化</p>
        
        
          
        
        <div class="index-excerpt" >
          <div class="index-text mb-1">深度学习或者机器学习中一个老生常谈的问题就是调参，许多机器学习算法工程师经常戏称自己为“炼丹工程师”，调参过程也就变成了“炼丹”。何谓炼丹？如何调配出一副“仙药”只能靠尝试不同的配方，根据最终的效果(会不会吃死人)来进行改进。
然后大家渐渐感觉这种炼丹方法不太行。太上老君这种老头为什么能炼金丹？主要是他活得太久，尝试的错误太多，经验也就渐渐积累起来了，放到算法工程师身上情况同样适应，经验丰富的调参手往往一发入魂，新手就是摸着石头过河，难以估计深浅。所以，大家都开始渐渐地意识到自动化调参的必要性，对于个人来说，可以节省大量的时间，去做更多更加有意义的事情(学习)。对公司来说，如果能够实现自动化超参数调整的话，就不必雇佣经验丰富的算法工程师来做相关工作，大大节省了人力成本。
目前来讲，主流的自动调参算法有Grid Search(网格搜索)、Random Search(随机搜索)、Bayesian Optimization(贝叶斯优化)。随机搜索是最简单的调参算法，但是由于是随机的，往往效果不稳定，波动比较大。网格搜索需要人为定义搜索空间，并且对所有参数进行组合，仍然依赖经验，搜索的时间成本</div>
        </div>
      </a>

      <div>
        
          <i class="iconfont icon-riqi2"></i>&nbsp;2019-12-10&nbsp;&nbsp;
        
        
        
          <i class="iconfont icon-tag"></i>
          
            <a href="/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0">深度学习</a>&nbsp;
          
        
      </div>
    </div>
  </div>

  <div class="row mb-4 mx-auto">
    
    
      <div class="col-12 col-md-4 m-auto">
        <a href="/2019/11/30/two-stage-detection/" target="_self">
          <img src="/img/faster-RCNN.png" srcset="undefined" alt="两阶段目标检测算法" class="img-fluid rounded z-depth-3 index-thumbnails">
        </a>
      </div>
    
    <div class="col-12 col-md-8 m-auto">
      <a href="/2019/11/30/two-stage-detection/">
        <p class="h4 index-header">两阶段目标检测算法</p>
        
        
          
        
        <div class="index-excerpt" >
          <div class="index-text mb-1">在目标检测任务中，我们可以根据是否产生proposal将模型分为两个类别：单阶段(one-stage)目标检测算法和两阶段(two-stage)目标检测算法。
本文将整理介绍几种经典的两阶段目标检测算法(R-CNN, SPP Net, Fast R-CNN, Faster R-CNN)，主要从解决的问题、创新点、算法具体流程、仍存在的问题等方面进行一一阐述。
R-CNN时间：2014



解决的问题：
如何将深度学习应用于目标检测领域？

创新点：
首次将深度学习应用到目标检测领域，打破了之前几年时间内传统方法无法获得提升的困境，大大提高了目标检测算法的性能

算法流程：
1.输入图片2.对输入图片利用selective search算法产生大约2k个region proposal3.对所有的proposal进行warp操作固定大小，然后输入到预训练好的网络中获取feature4.利用线性SVM进行分类

存在的问题：
1.feature extraction阶段针对每一个proposal都需要通过神经网络计算对应的feature，计算量大2.region proposal、feat</div>
        </div>
      </a>

      <div>
        
          <i class="iconfont icon-riqi2"></i>&nbsp;2019-11-30&nbsp;&nbsp;
        
        
        
          <i class="iconfont icon-tag"></i>
          
            <a href="/tags/object%20detection">object detection</a>&nbsp;
          
        
      </div>
    </div>
  </div>

  <div class="row mb-4 mx-auto">
    
    
      <div class="col-12 col-md-4 m-auto">
        <a href="/2019/11/21/anchor/" target="_self">
          <img src="/img/anchor.png" srcset="undefined" alt="目标检测中的Anchor" class="img-fluid rounded z-depth-3 index-thumbnails">
        </a>
      </div>
    
    <div class="col-12 col-md-8 m-auto">
      <a href="/2019/11/21/anchor/">
        <p class="h4 index-header">目标检测中的Anchor</p>
        
        
          
        
        <div class="index-excerpt" >
          <div class="index-text mb-1">什么是Anchor？anchor机制是广泛应用于目标检测任务中的一种方法，anchor box指的是是一组预先定义好的不同长宽比的边界框，通过对这些不同长宽比的anchor进行微调，我们能够检测到对应不同尺寸的真实物体。


目标检测中的anchor




Anchor的作用是什么？考虑到图像中会出现不同尺寸(scale)，不同长宽比(aspect ratio)的物体，而我们神经网络的输出是一组同样scale的feature map和一组同样的weights，这样的情况下让其预测不同scale和aspect ratio的物体就相对来说比较困难。如图所示：


图像中的多尺度物体


Faster-RCNN中首先引入anchor的概念，论文中有这样一段话:

In contrast to prevalent methods [8], [9], [1], [2] that use pyramids of images (Figure 1, a) or pyramids of filters (Figure 1, b), we introduce novel “anchor” boxes </div>
        </div>
      </a>

      <div>
        
          <i class="iconfont icon-riqi2"></i>&nbsp;2019-11-21&nbsp;&nbsp;
        
        
        
          <i class="iconfont icon-tag"></i>
          
            <a href="/tags/object%20detection">object detection</a>&nbsp;
          
        
      </div>
    </div>
  </div>

  <div class="row mb-4 mx-auto">
    
    
      <div class="col-12 col-md-4 m-auto">
        <a href="/2019/11/04/dl-recipe/" target="_self">
          <img src="/img/param-tune.jpeg" srcset="undefined" alt="翻译：A Recipe for Training Neural Networks" class="img-fluid rounded z-depth-3 index-thumbnails">
        </a>
      </div>
    
    <div class="col-12 col-md-8 m-auto">
      <a href="/2019/11/04/dl-recipe/">
        <p class="h4 index-header">翻译：A Recipe for Training Neural Networks</p>
        
        
          
        
        <div class="index-excerpt" >
          <div class="index-text mb-1">原文链接：A Recipe for Training Neural Networks
引言&emsp; 几周之前我发了一条推特“最常见的神经网络错误”，其中列出了几条在训练神经网络过程中常见的陷阱。这条推特比我预想的得到了更多的关注。很明显，很多人都亲身经历过”我们的网络能够work”与”我们的网络实现了state of the art的效果”之间的巨大性能差异。
&emsp; 所以我觉得如果将这条推特通过博客的形式来延伸一下应该很有趣。但是我并不打算列举出那些常见的错误，我想更加深层次的探讨一下如何去避免这些错误（或者迅速修正他们）。
方法1.熟悉你的数据&emsp; 构建神经网络的第一步不是去写代码，而是充分的观察你的数据，这一步至关重要。我通常喜欢花费大量时间（小时为单位）来浏览数据样本，从而了解他们的分布规律并寻找数据中可能存在的模式。幸运的是，人类的大脑是非常擅长做这类工作的。通过浏览样本，可能这次我发现数据中包含重复样本，下一次我就能发现损坏的图像/标签。同时我还会寻找数据中的不平衡和偏差问题。通常，我会按照自己的方法将数据分类，这暗示了我们最终要探索的各种数据中的结构。例</div>
        </div>
      </a>

      <div>
        
          <i class="iconfont icon-riqi2"></i>&nbsp;2019-11-04&nbsp;&nbsp;
        
        
        
          <i class="iconfont icon-tag"></i>
          
            <a href="/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0">深度学习</a>&nbsp;
          
        
      </div>
    </div>
  </div>

  <div class="row mb-4 mx-auto">
    
    
      <div class="col-12 col-md-4 m-auto">
        <a href="/2019/10/29/Gradient-Accumulation/" target="_self">
          <img src="/img/gradient.jpeg" srcset="undefined" alt="梯度累加(Gradient Accumulation)" class="img-fluid rounded z-depth-3 index-thumbnails">
        </a>
      </div>
    
    <div class="col-12 col-md-8 m-auto">
      <a href="/2019/10/29/Gradient-Accumulation/">
        <p class="h4 index-header">梯度累加(Gradient Accumulation)</p>
        
        
          
        
        <div class="index-excerpt" >
          <div class="index-text mb-1">&emsp;  我们在训练神经网络的时候，超参数batch size的大小会对最终的模型效果产生很大的影响。一定条件下，batch size设置的越大，模型就会越稳定。batch size的值通常设置在 8-32 之间，但是当我们做一些计算量需求大的任务(例如语义分割、GAN等)或者输入图片尺寸太大的时候，我们的batch size往往只能设置为2或者4，否则就会出现 “CUDA OUT OF MEMORY” 的不可抗力报错。  
&emsp;  贫穷是促进人类进步的阶梯，如何在有限的计算资源的条件下，训练时采用更大的batch size呢？这就是梯度累加(Gradient Accumulation)技术了。  
&emsp; 我们以Pytorch为例，一个神经网络的训练过程通常如下：
    for i, (inputs, labels) in enumerate(trainloader):

        optimizer.zero_grad()                   # 梯度清零
        outputs = net(inputs)            </div>
        </div>
      </a>

      <div>
        
          <i class="iconfont icon-riqi2"></i>&nbsp;2019-10-29&nbsp;&nbsp;
        
        
        
          <i class="iconfont icon-tag"></i>
          
            <a href="/tags/pytorch">pytorch</a>&nbsp;
          
        
      </div>
    </div>
  </div>



  <nav aria-label="index posts navigation">
    <span class="pagination pg-blue justify-content-center mt-5" id="pagination">
      <a class="extend prev" rel="prev" href="/"><i class="fas fa-angle-double-left"></i></a><a class="page-number" href="/">1</a><span class="page-number current">2</span>
    </span>
  </nav>
  
  <script>
    for (ele of document.getElementById("pagination").getElementsByClassName("page-number")) {
      ele.href += '#board';
    }
  </script>



              </div>
            </div>
          </div>
        </div>
      </div>
    
  </main>

  
    <a class="z-depth-1" id="scroll-top-button" href="#" role="button">
      <i class="fa fa-chevron-up scroll-top-arrow" aria-hidden="true"></i>
    </a>
  

  
    <div class="modal fade" id="modalSearch" tabindex="-1" role="dialog" aria-labelledby="ModalLabel"
     aria-hidden="true">
  <div class="modal-dialog modal-dialog-scrollable modal-lg" role="document">
    <div class="modal-content">
      <div class="modal-header text-center">
        <h4 class="modal-title w-100 font-weight-bold">Search</h4>
        <button type="button" id="local-search-close" class="close" data-dismiss="modal" aria-label="Close">
          <span aria-hidden="true">&times;</span>
        </button>
      </div>
      <div class="modal-body mx-3">
        <div class="md-form mb-5">
          <input type="text" id="local-search-input" class="form-control validate">
          <label data-error="x" data-success="v"
                 for="local-search-input">keyword</label>
        </div>
        <div class="list-group" id="local-search-result"></div>
      </div>
    </div>
  </div>
</div>
  

  <footer class="mt-5">
  <div class="text-center py-3">
    <a href="https://hexo.io" target="_blank" rel="nofollow noopener"><b>Hexo</b></a>
    <i class="iconfont icon-love"></i>
    <a href="https://github.com/fluid-dev/hexo-theme-fluid" target="_blank" rel="nofollow noopener"> <b>Fluid</b></a>
    <br>

    
  
  
  <br>



    

  </div>
</footer>

<!-- SCRIPTS -->
<script src="/lib/jquery/jquery.min.js" ></script>
<script src="/lib/popper/popper.min.js" ></script>
<script src="/lib/bootstrap/js/bootstrap.min.js" ></script>
<script src="/lib/mdbootstrap/js/mdb.min.js" ></script>
<script src="/js/main.js" ></script>


  <script src="/js/lazyload.js" ></script>





  <script src="/lib/smooth-scroll/smooth-scroll.min.js" ></script>



  <script async src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js" ></script>


<!-- Plugins -->


  

  

  

  

  




  <script src="/lib/prettify/prettify.min.js" ></script>
  <script>
    $(document).ready(function () {
      $('pre').addClass('prettyprint  linenums');
      prettyPrint();
    })
  </script>



  <script src="/lib/typed/typed.min.js" ></script>
  <script>
    var typed = new Typed('#subtitle', {
      strings: [
        '  ',
        "生活就是一个缓慢受锤的过程&nbsp;",
      ],
      cursorChar: "_",
      typeSpeed: 70,
      loop: false,
    });
    typed.stop();
    $(document).ready(function () {
      $(".typed-cursor").addClass("h2");
      typed.start();
    });
  </script>



  <script src="/lib/anchor/anchor.min.js" ></script>
  <script>
    anchors.options = {
      placement: "right",
      visible: "false",
      
    };
    var el = "h1,h2,h3,h4,h5,h6".split(",");
    var res = [];
    for (item of el) {
      res.push(".markdown-body > " + item)
    }
    anchors.add(res.join(", "))
  </script>



  <script src="/js/local-search.js" ></script>
  <script>
    var path = "/local-search.xml";
    var inputArea = document.querySelector("#local-search-input");
    inputArea.onclick = function () {
      getSearchFile(path);
      this.onclick = null
    }
  </script>



  <script src="/lib/fancybox/jquery.fancybox.min.js" ></script>
  <script>
    $("#post img:not(.no-zoom img, img[no-zoom])").each(
      function () {
        var element = document.createElement("a");
        $(element).attr("data-fancybox", "images");
        $(element).attr("href", $(this).attr("src"));
        $(this).wrap(element);
      }
    );
  </script>



  

  
    <!-- MathJax -->
    <script type="text/x-mathjax-config">
      MathJax.Hub.Config({
          tex2jax: {
              inlineMath: [ ['$','$'], ["\\(","\\)"]  ],
              processEscapes: true,
              skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
          }
      });

      MathJax.Hub.Queue(function() {
          var all = MathJax.Hub.getAllJax(), i;
          for(i=0; i < all.length; i += 1) {
              all[i].SourceElement().parentNode.className += ' has-jax';
          }
      });

    </script>

    <script src="https://cdn.staticfile.org/mathjax/2.7.6/MathJax.js?config=TeX-MML-AM_CHTML" ></script>

  





</body>
</html>
