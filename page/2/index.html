<!DOCTYPE html>
<html lang="en | zh-CN | zh-TW">





<head>
  <meta charset="UTF-8">
  <link rel="apple-touch-icon" sizes="76x76" href="/img/apple-touch-icon.png">
  <link rel="icon" type="image/png" href="/img/leaf.jpeg">
  <meta name="viewport"
        content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no, shrink-to-fit=no">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <meta name="description" content="">
  <meta name="author" content="cowarder">
  <meta name="keywords" content="">
  <title>cowarder</title>

  <link rel="stylesheet" href="/lib/font-awesome/css/all.min.css"  >
<link rel="stylesheet" href="/lib/bootstrap/css/bootstrap.min.css"  >
<link rel="stylesheet" href="/lib/mdbootstrap/css/mdb.min.css"  >
<link rel="stylesheet" href="/lib/github-markdown/github-markdown.min.css"  >
<link rel="stylesheet" href="//at.alicdn.com/t/font_1067060_qzomjdt8bmp.css">


  <link rel="stylesheet" href="/lib/prettify/github-v2.min.css"  >

<link rel="stylesheet" href="/css/main.css"  >


  <link rel="stylesheet" href="/lib/fancybox/jquery.fancybox.min.css"  >


</head>


<body>
  <header style="height: 100vh;">
    <nav id="navbar" class="navbar fixed-top  navbar-expand-lg navbar-dark scrolling-navbar">
  <div class="container">
    <a class="navbar-brand"
       href="/">&nbsp;<strong>cowarder</strong>&nbsp;</a>

    <button id="navbar-toggler-btn" class="navbar-toggler" type="button" data-toggle="collapse"
            data-target="#navbarSupportedContent"
            aria-controls="navbarSupportedContent" aria-expanded="false" aria-label="Toggle navigation">
      <div class="animated-icon"><span></span><span></span><span></span></div>
    </button>

    <!-- Collapsible content -->
    <div class="collapse navbar-collapse" id="navbarSupportedContent">
      <ul class="navbar-nav ml-auto text-center">
        
          
          
          <li class="nav-item">
            <a class="nav-link" href="/">Home</a>
          </li>
        
          
          
          <li class="nav-item">
            <a class="nav-link" href="/archives/">Archives</a>
          </li>
        
          
          
          <li class="nav-item">
            <a class="nav-link" href="/tags/">Tags</a>
          </li>
        
          
          
          <li class="nav-item">
            <a class="nav-link" href="/about/">About</a>
          </li>
        
        
          <li class="nav-item" id="search-btn">
            <a class="nav-link" data-toggle="modal" data-target="#modalSearch">&nbsp;&nbsp;<i
                class="iconfont icon-search"></i>&nbsp;&nbsp;</a>
          </li>
        
      </ul>
    </div>
  </div>


</nav>

    <div class="view intro-2" id="background"
         style="background: url('/img/main_page.jpg')no-repeat center center;
           background-size: cover;
           background-attachment: fixed;">
      <div class="full-bg-img">
        <div class="mask rgba-black-light flex-center">
          <div class="container text-center white-text fadeInUp">
            <span class="h2" id="subtitle">
              
            </span>

            
          </div>

          
            <div class="scroll-down-bar">
              <i class="fas fa-angle-down scroll-down-arrow"></i>
            </div>
          
        </div>
      </div>
    </div>
  </header>

  <main>
    
      <div class="container nopadding-md">
        <div class="py-5 z-depth-3" id="board">
          
          <div class="container">
            <div class="row">
              <div class="col-12 col-md-10 m-auto">
                


  <div class="row mb-4 mx-auto">
    
    
      <div class="col-12 col-md-4 m-auto">
        <a href="/2020/04/15/small-od/" target="_self">
          <img src="/img/sod.jpeg" srcset="undefined" alt="小目标检测(Small Object Detection)" class="img-fluid rounded z-depth-3 index-thumbnails">
        </a>
      </div>
    
    <div class="col-12 col-md-8 m-auto">
      <a href="/2020/04/15/small-od/">
        <p class="h4 index-header">小目标检测(Small Object Detection)</p>
        
        
          
        
        <div class="index-excerpt" >
          <div class="index-text mb-1">现今存在的通用目标检测方法大多数在一般大小的物体上面检测效果较好，但是针对小物体的检测效果较差。目前的检测方法基本基于深度学习，而神经网络是由逐层卷积网络组成的，我们以一个常用的分类神经网络举例。


  
    Generic image classification baseline.
  


网络中包含有一系列的卷积+pooling层，在检测网络中，如YOLO、SSD、Faster R-CNN等中也会大量使用这种类似结构，我们利用神经网络将600x600的输入转化为30x30的特征。但是这样的网络结果造成的一个非常直观的问题，如果在原始(600x600)图片中很小的物体，经过卷积映射为低维特征(30x30)之后，小物体特征几乎可以忽略不计，甚至完全消失，在训练过程中，网络在靠后的特征层中就失去了小物体的监督信息，因此就会造成检测性能的下降。
本文旨在总结几种常见的解决小物体检测的方法，大体可以分为四类：多尺度特征学习、数据增强、采用训练策略、基于GAN的检测。
1.多尺度特征学习如何去处理特征尺度问题对于小物体检测十分重要，大体可以分为7类：特征图像金字塔、单尺度特征、金字塔</div>
        </div>
      </a>

      <div>
        
          <i class="iconfont icon-riqi2"></i>&nbsp;2020-04-15&nbsp;&nbsp;
        
        
        
          <i class="iconfont icon-tag"></i>
          
            <a href="/tags/object%20detection">object detection</a>&nbsp;
          
        
      </div>
    </div>
  </div>

  <div class="row mb-4 mx-auto">
    
    
      <div class="col-12 col-md-4 m-auto">
        <a href="/2020/03/04/batch-norm/" target="_self">
          <img src="/img/norm.png" srcset="undefined" alt="Batch Normalization" class="img-fluid rounded z-depth-3 index-thumbnails">
        </a>
      </div>
    
    <div class="col-12 col-md-8 m-auto">
      <a href="/2020/03/04/batch-norm/">
        <p class="h4 index-header">Batch Normalization</p>
        
        
          
        
        <div class="index-excerpt" >
          <div class="index-text mb-1">这篇文章来回顾一下深度学习网络模型中常见的操作:Batch Normalization。Batch Normalization是在2015年由Szegedy提出的。主要是解决神经网络中存在的Interval Covariate Shift问题。除了回顾batch normalization有关原理，本文也会介绍几种常见的对于Batch Normalization的改进。
Interval Covariate Shift在Batch Normalization出现之前，训练一个层数较多的神经网络模型是十分困难的，经常出现不收敛的情况，其中重要的原因是，神经网络涉及到很多层的叠加，每一层的参数变化会导致上层输出的改变，经过层层叠加，底层即便是一个微小的波动，也会导致上层输入特征的巨大变化，这就使得上层参数需要不断改变去适应由底层传来的特征，为了使得模型能够收敛，我们需要更加仔细地选择学习率、权重初始化、尽可能选择更好的参数更新策略。
在统计机器学习中一个经典假设是源空间(source domain)和目标空间(target domain)的数据分布是一致的。而covariate shift</div>
        </div>
      </a>

      <div>
        
          <i class="iconfont icon-riqi2"></i>&nbsp;2020-03-04&nbsp;&nbsp;
        
        
        
          <i class="iconfont icon-tag"></i>
          
            <a href="/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0">深度学习</a>&nbsp;
          
        
      </div>
    </div>
  </div>

  <div class="row mb-4 mx-auto">
    
    
      <div class="col-12 col-md-4 m-auto">
        <a href="/2020/02/25/poly-yolo/" target="_self">
          <img src="/img/poly.jpeg" srcset="undefined" alt="Poly-YOLO" class="img-fluid rounded z-depth-3 index-thumbnails">
        </a>
      </div>
    
    <div class="col-12 col-md-8 m-auto">
      <a href="/2020/02/25/poly-yolo/">
        <p class="h4 index-header">Poly-YOLO</p>
        
        
          
        
        <div class="index-excerpt" >
          <div class="index-text mb-1">论文阅读：POLY-YOLO: HIGHER SPEED, MORE PRECISE DETECTION AND INSTANCE SEGMENTATION FOR YOLOV3
什么是Poly-YOLO简言之，Poly-YOLO是YOLOv3的一个改进版本，产生的实际效果与Mask-RCNN相似，但是Poly-YOLO更快。文章作者声称Poly-YOLO相较于YOLOv3速度更快，同时mAP提升40%。Poly-YOLO的轻量级版本-Poly-YOLO lite，与YOLOv3具有相似的精度，但是模型大小仅为三分之一，而速度为两倍，因此更加适应于嵌入式设备。代码
YOLOv3中存在的问题本文从分析YOLOv3论文中存在的两个问题，进而进行改进。
（问题1）标签重写(label rewriting)。在预处理阶段，经常出现label被另外一个label重写的情况，这样就会导致一些正样本没有标签，模型也就不会被训练去检测它们，因此会对性能产生很大影响。以YOLOv3为例，其有三个scale，分别对应检测大、中、小尺寸的物体，每个scale的feature map被划分为s*s的grid，</div>
        </div>
      </a>

      <div>
        
          <i class="iconfont icon-riqi2"></i>&nbsp;2020-02-25&nbsp;&nbsp;
        
        
        
          <i class="iconfont icon-tag"></i>
          
            <a href="/tags/%E8%AE%BA%E6%96%87">论文</a>&nbsp;
          
        
      </div>
    </div>
  </div>

  <div class="row mb-4 mx-auto">
    
    
      <div class="col-12 col-md-4 m-auto">
        <a href="/2020/02/11/cvpr2020/" target="_self">
          <img src="/img/cvpr2020.png" srcset="undefined" alt="cvpr2020" class="img-fluid rounded z-depth-3 index-thumbnails">
        </a>
      </div>
    
    <div class="col-12 col-md-8 m-auto">
      <a href="/2020/02/11/cvpr2020/">
        <p class="h4 index-header">cvpr2020</p>
        
        
          
        
        <div class="index-excerpt" >
          <div class="index-text mb-1">这篇文章主要对CVPR2020中涉及到的目标检测的文章做一个简短总结，提炼总体文章思路，以备查阅。
《Few-Shot Object Detection with Attention-RPN and Multi-Relation Detector》
小样本学习的文章。目标检测需要大量标注工作，利用少量标注样本训练模型得到更好的效果在一些任务上面更加需要。文章中主要有两点贡献，首先作者提出了一个新的网络（带有注意力机制的RPN和多关系检测器的小样本目标检测网络），在不用重新训练和微调的情况下检测新的物体，第二点贡献在于设计了一个新的数据集(FSOD)，其中包括1000个类别，每个类别只有很少的图片，利用这个数据集，模型相较于COCO数据集上面进行训练，取得了更好的效果。在few-shot learning任务中，我们一般将带有标签的图片称为support image，等待分割的图片称为query image，注意力机制RPN通过关注给定的支持类别来过滤掉其他类别的对象建议，然后多关系检测器将查询建议与支持图像进行匹配。
《Bridging the Gap Between Anchor-b</div>
        </div>
      </a>

      <div>
        
          <i class="iconfont icon-riqi2"></i>&nbsp;2020-02-11&nbsp;&nbsp;
        
        
        
          <i class="iconfont icon-tag"></i>
          
            <a href="/tags/object%20detection">object detection</a>&nbsp;
          
        
      </div>
    </div>
  </div>

  <div class="row mb-4 mx-auto">
    
    
      <div class="col-12 col-md-4 m-auto">
        <a href="/2020/01/28/mobile/" target="_self">
          <img src="/img/mobilenet.png" srcset="undefined" alt="MobileNet" class="img-fluid rounded z-depth-3 index-thumbnails">
        </a>
      </div>
    
    <div class="col-12 col-md-8 m-auto">
      <a href="/2020/01/28/mobile/">
        <p class="h4 index-header">MobileNet</p>
        
        
          
        
        <div class="index-excerpt" >
          <div class="index-text mb-1">卷积神经网络在计算机视觉领域已经得到了广泛应用，在各种视觉任务中都取得了比较好的效果。大趋势是通过不断增加网络深度、设计更加复杂的网络来提高模型精度。但是随着网络模型的增加，模型存储需要的内存以及运行需要的算力也在不断增加。在某些实际应用领域，例如嵌入式设备，这样庞大而复杂的网络是很难被应用的，一方面是模型过于庞大，面临内存不足的问题，而另外一方面，这些应用领域要求延迟低，而网络参数越多计算量越大，延迟就会越高。因此研究小而且高效的网络对工业界实际应用具有非常大的意义。
考虑到硬件设备的限制，目前在网络研究方面主要分为两个方面，一是对于训练好的模型进行压缩，减少参数量。另外一种是直接设计一个小的模型进行训练。其目标在于在保证模型精度的情况下减少参数数目，同时提升模型精度。本文所做的改进属于后者。
深度可分离卷积(depthwise seperable convolution)MobileNet中的基本组建是深度可分离卷积(depthwise seperable convolution)，首先我们需要分析一个传统的卷积操作。

 


假设我们有一个1212的输入特征图，通道数为3($D</div>
        </div>
      </a>

      <div>
        
          <i class="iconfont icon-riqi2"></i>&nbsp;2020-01-28&nbsp;&nbsp;
        
        
        
      </div>
    </div>
  </div>

  <div class="row mb-4 mx-auto">
    
    
      <div class="col-12 col-md-4 m-auto">
        <a href="/2020/01/15/activation/" target="_self">
          <img src="/img/relu.png" srcset="undefined" alt="论文阅读《Delving Deep into Rectifiers Surpassing Human-Level Performance on ImageNet Classification》" class="img-fluid rounded z-depth-3 index-thumbnails">
        </a>
      </div>
    
    <div class="col-12 col-md-8 m-auto">
      <a href="/2020/01/15/activation/">
        <p class="h4 index-header">论文阅读《Delving Deep into Rectifiers Surpassing Human-Level Performance on ImageNet Classification》</p>
        
        
          
        
        <div class="index-excerpt" >
          <div class="index-text mb-1">最近抽空看了一下何凯明2015年的文章《Delving Deep into Rectifiers: Surpassing Human-Level Performance on ImageNet Classification》，这篇文章里面主要分为两个部分，第一部分作者提出了PReLU激活函数，第二部分提出了Kaiming参数初始化方法，关于Kaiming初始化，我们已经在上一篇文章中做了推倒，这里不再赘述。PReLU方法为ReLU方法的改进版本，因此，本文不仅仅局限于这篇文章，而是借此对几种常见的激活函数进行探讨
Sigmoid函数和Tanh函数在神经网络发展初期，Sigmoid函数和Tanh函数是最常见的激活函数，它们的函数图像如下图所示：




其中蓝色的线表示Tanh函数，绿色的线表示Sigmoid函数，可以看到，Tanh激活函数实际上相当于Sigmoid函数的平移
$$Sigmoid:f(z)=\frac{1}{1+e^{-z}}$$
$$Tanh:f(z)=\frac{e^z-e^{-z}}{e^z+e^{-z}}$$
但是在研究过中发现，Sigmoid函数和Tanh函数作</div>
        </div>
      </a>

      <div>
        
          <i class="iconfont icon-riqi2"></i>&nbsp;2020-01-15&nbsp;&nbsp;
        
        
        
          <i class="iconfont icon-tag"></i>
          
            <a href="/tags/%E8%AE%BA%E6%96%87">论文</a>&nbsp;
          
        
      </div>
    </div>
  </div>

  <div class="row mb-4 mx-auto">
    
    
      <div class="col-12 col-md-4 m-auto">
        <a href="/2020/01/07/param-init/" target="_self">
          <img src="/img/kaiming.png" srcset="undefined" alt="参数初始化" class="img-fluid rounded z-depth-3 index-thumbnails">
        </a>
      </div>
    
    <div class="col-12 col-md-8 m-auto">
      <a href="/2020/01/07/param-init/">
        <p class="h4 index-header">参数初始化</p>
        
        
          
        
        <div class="index-excerpt" >
          <div class="index-text mb-1">深度学习中的网络初始化指的是在训练网络之前，对每个节点的权重和偏置进行初始化的过程，一个参数的初始化关系到网络是否能够训练出好的结果以及模型收敛的速度。本文简要介绍两种常见的参数初始化方法的推导过程及原理。
Xavier初始化神经网络做的任务无非是将原本的样本稳定映射为它的类别，也就是将样本空间映射为类别空间，如果样本空间和类别空间差距过大，例如类别空间特别稠密，样本空间特别稀疏，那么在类别空间得到的用于反向传播的误差丢给样本空间之后就会变得微不足道，反之，如果类别空间特别稀疏，样本空间特别稠密，在类别空间得到的误差丢给样本空间之后会造成爆炸性的影响，导致模型梯度爆炸，无法收敛。因此，我们需要让类别空间和样本空间之间的分布差异不要太大，也就是它们之间的方差尽可能相等，这就是Xavier初始化的出发点。
对于 y. = wx ，假设有：$$Var(Y) = Var(w_iX)=Var(w_i)*Var(X)+E^2(X)*Var(w_i)+E^2(w_i)*Var(X)\qquad(1)$$
当$X, w_i$都符合均值为0的正态分布时，$E(X),E(w_i)$均为0，公式进一步简化为</div>
        </div>
      </a>

      <div>
        
          <i class="iconfont icon-riqi2"></i>&nbsp;2020-01-07&nbsp;&nbsp;
        
        
        
          <i class="iconfont icon-tag"></i>
          
            <a href="/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0">深度学习</a>&nbsp;
          
        
      </div>
    </div>
  </div>

  <div class="row mb-4 mx-auto">
    
    
      <div class="col-12 col-md-4 m-auto">
        <a href="/2019/12/25/NMS/" target="_self">
          <img src="/img/nms.png" srcset="undefined" alt="NMS(非极大值抑制算法)" class="img-fluid rounded z-depth-3 index-thumbnails">
        </a>
      </div>
    
    <div class="col-12 col-md-8 m-auto">
      <a href="/2019/12/25/NMS/">
        <p class="h4 index-header">NMS(非极大值抑制算法)</p>
        
        
          
        
        <div class="index-excerpt" >
          <div class="index-text mb-1">什么是NMS算法？非极大值抑制NMS(Non-maximum Suppression)算法是目标检测任务中一个不可或缺的模块，目标检测的任务是输入一幅图片，利用不同大小、不同尺寸的边界框找出图片中对应的目标物体。

 


但是在实际的检测过程中，我们的检测算法往往会针对一个目标物体，框出许多边界框。

 


但是我们最终对于每个物体实例，最理想的情况下只需要保留一个最佳的边界框，这就应用到了我们的NMS算法。NMS算法通过选定一个得分(confidence score)最高的边界框，过滤掉(抑制)与其相近的其他边界框，并给出相应框对应的类别。

 


NMS算法实现

输入：边界框集合$\textbf{B}$，对应的IOU阈值$\textbf{T}$
新建一个空的集合$\textbf{D}$，用于保存最终的结果
将$\textbf{B}$中的边界框按照得分由高到低排序
选取$\textbf{B}$中得分最高的边界框$\textbf{m}$，放到$\textbf{D}$中
计算$\textbf{B}$中剩余边界框与$\textbf{m}$的IOU值，IOU大于$\textbf{T}</div>
        </div>
      </a>

      <div>
        
          <i class="iconfont icon-riqi2"></i>&nbsp;2019-12-25&nbsp;&nbsp;
        
        
        
          <i class="iconfont icon-tag"></i>
          
            <a href="/tags/object%20detection">object detection</a>&nbsp;
          
        
      </div>
    </div>
  </div>

  <div class="row mb-4 mx-auto">
    
    
      <div class="col-12 col-md-4 m-auto">
        <a href="/2019/12/10/bayes-optim/" target="_self">
          <img src="/img/bayes.png" srcset="undefined" alt="贝叶斯优化" class="img-fluid rounded z-depth-3 index-thumbnails">
        </a>
      </div>
    
    <div class="col-12 col-md-8 m-auto">
      <a href="/2019/12/10/bayes-optim/">
        <p class="h4 index-header">贝叶斯优化</p>
        
        
          
        
        <div class="index-excerpt" >
          <div class="index-text mb-1">深度学习或者机器学习中一个老生常谈的问题就是调参，许多机器学习算法工程师经常戏称自己为“炼丹工程师”，调参过程也就变成了“炼丹”。何谓炼丹？如何调配出一副“仙药”只能靠尝试不同的配方，根据最终的效果(会不会吃死人)来进行改进。
然后大家渐渐感觉这种炼丹方法不太行。太上老君这种老头为什么能炼金丹？主要是他活得太久，尝试的错误太多，经验也就渐渐积累起来了，放到算法工程师身上情况同样适应，经验丰富的调参手往往一发入魂，新手就是摸着石头过河，难以估计深浅。所以，大家都开始渐渐地意识到自动化调参的必要性，对于个人来说，可以节省大量的时间，去做更多更加有意义的事情(学习)。对公司来说，如果能够实现自动化超参数调整的话，就不必雇佣经验丰富的算法工程师来做相关工作，大大节省了人力成本。
目前来讲，主流的自动调参算法有Grid Search(网格搜索)、Random Search(随机搜索)、Bayesian Optimization(贝叶斯优化)。随机搜索是最简单的调参算法，但是由于是随机的，往往效果不稳定，波动比较大。网格搜索需要人为定义搜索空间，并且对所有参数进行组合，仍然依赖经验，搜索的时间成本</div>
        </div>
      </a>

      <div>
        
          <i class="iconfont icon-riqi2"></i>&nbsp;2019-12-10&nbsp;&nbsp;
        
        
        
          <i class="iconfont icon-tag"></i>
          
            <a href="/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0">深度学习</a>&nbsp;
          
        
      </div>
    </div>
  </div>

  <div class="row mb-4 mx-auto">
    
    
      <div class="col-12 col-md-4 m-auto">
        <a href="/2019/11/30/two-stage-detection/" target="_self">
          <img src="/img/faster-RCNN.png" srcset="undefined" alt="两阶段目标检测算法" class="img-fluid rounded z-depth-3 index-thumbnails">
        </a>
      </div>
    
    <div class="col-12 col-md-8 m-auto">
      <a href="/2019/11/30/two-stage-detection/">
        <p class="h4 index-header">两阶段目标检测算法</p>
        
        
          
        
        <div class="index-excerpt" >
          <div class="index-text mb-1">在目标检测任务中，我们可以根据是否产生proposal将模型分为两个类别：单阶段(one-stage)目标检测算法和两阶段(two-stage)目标检测算法。
本文将整理介绍几种经典的两阶段目标检测算法(R-CNN, SPP Net, Fast R-CNN, Faster R-CNN)，主要从解决的问题、创新点、算法具体流程、仍存在的问题等方面进行一一阐述。
R-CNN时间：2014



解决的问题：
如何将深度学习应用于目标检测领域？

创新点：
首次将深度学习应用到目标检测领域，打破了之前几年时间内传统方法无法获得提升的困境，大大提高了目标检测算法的性能

算法流程：
1.输入图片2.对输入图片利用selective search算法产生大约2k个region proposal3.对所有的proposal进行warp操作固定大小，然后输入到预训练好的网络中获取feature4.利用线性SVM进行分类

存在的问题：
1.feature extraction阶段针对每一个proposal都需要通过神经网络计算对应的feature，计算量大2.region proposal、feat</div>
        </div>
      </a>

      <div>
        
          <i class="iconfont icon-riqi2"></i>&nbsp;2019-11-30&nbsp;&nbsp;
        
        
        
          <i class="iconfont icon-tag"></i>
          
            <a href="/tags/object%20detection">object detection</a>&nbsp;
          
        
      </div>
    </div>
  </div>



  <nav aria-label="index posts navigation">
    <span class="pagination pg-blue justify-content-center mt-5" id="pagination">
      <a class="extend prev" rel="prev" href="/"><i class="fas fa-angle-double-left"></i></a><a class="page-number" href="/">1</a><span class="page-number current">2</span><a class="page-number" href="/page/3/">3</a><a class="extend next" rel="next" href="/page/3/"><i class="fas fa-angle-double-right"></i></a>
    </span>
  </nav>
  
  <script>
    for (ele of document.getElementById("pagination").getElementsByClassName("page-number")) {
      ele.href += '#board';
    }
  </script>



              </div>
            </div>
          </div>
        </div>
      </div>
    
  </main>

  
    <a class="z-depth-1" id="scroll-top-button" href="#" role="button">
      <i class="fa fa-chevron-up scroll-top-arrow" aria-hidden="true"></i>
    </a>
  

  
    <div class="modal fade" id="modalSearch" tabindex="-1" role="dialog" aria-labelledby="ModalLabel"
     aria-hidden="true">
  <div class="modal-dialog modal-dialog-scrollable modal-lg" role="document">
    <div class="modal-content">
      <div class="modal-header text-center">
        <h4 class="modal-title w-100 font-weight-bold">Search</h4>
        <button type="button" id="local-search-close" class="close" data-dismiss="modal" aria-label="Close">
          <span aria-hidden="true">&times;</span>
        </button>
      </div>
      <div class="modal-body mx-3">
        <div class="md-form mb-5">
          <input type="text" id="local-search-input" class="form-control validate">
          <label data-error="x" data-success="v"
                 for="local-search-input">keyword</label>
        </div>
        <div class="list-group" id="local-search-result"></div>
      </div>
    </div>
  </div>
</div>
  

  <footer class="mt-5">
  <div class="text-center py-3">
    <a href="https://hexo.io" target="_blank" rel="nofollow noopener"><b>Hexo</b></a>
    <i class="iconfont icon-love"></i>
    <a href="https://github.com/fluid-dev/hexo-theme-fluid" target="_blank" rel="nofollow noopener"> <b>Fluid</b></a>
    <br>

    
  
  
  <br>



    

  </div>
</footer>

<!-- SCRIPTS -->
<script src="/lib/jquery/jquery.min.js" ></script>
<script src="/lib/popper/popper.min.js" ></script>
<script src="/lib/bootstrap/js/bootstrap.min.js" ></script>
<script src="/lib/mdbootstrap/js/mdb.min.js" ></script>
<script src="/js/main.js" ></script>


  <script src="/js/lazyload.js" ></script>





  <script src="/lib/smooth-scroll/smooth-scroll.min.js" ></script>



  <script async src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js" ></script>


<!-- Plugins -->


  

  

  

  

  




  <script src="/lib/prettify/prettify.min.js" ></script>
  <script>
    $(document).ready(function () {
      $('pre').addClass('prettyprint  linenums');
      prettyPrint();
    })
  </script>



  <script src="/lib/typed/typed.min.js" ></script>
  <script>
    var typed = new Typed('#subtitle', {
      strings: [
        '  ',
        "生活就是一个缓慢受锤的过程&nbsp;",
      ],
      cursorChar: "_",
      typeSpeed: 70,
      loop: false,
    });
    typed.stop();
    $(document).ready(function () {
      $(".typed-cursor").addClass("h2");
      typed.start();
    });
  </script>



  <script src="/lib/anchor/anchor.min.js" ></script>
  <script>
    anchors.options = {
      placement: "right",
      visible: "false",
      
    };
    var el = "h1,h2,h3,h4,h5,h6".split(",");
    var res = [];
    for (item of el) {
      res.push(".markdown-body > " + item)
    }
    anchors.add(res.join(", "))
  </script>



  <script src="/js/local-search.js" ></script>
  <script>
    var path = "/local-search.xml";
    var inputArea = document.querySelector("#local-search-input");
    inputArea.onclick = function () {
      getSearchFile(path);
      this.onclick = null
    }
  </script>



  <script src="/lib/fancybox/jquery.fancybox.min.js" ></script>
  <script>
    $("#post img:not(.no-zoom img, img[no-zoom])").each(
      function () {
        var element = document.createElement("a");
        $(element).attr("data-fancybox", "images");
        $(element).attr("href", $(this).attr("src"));
        $(this).wrap(element);
      }
    );
  </script>



  

  
    <!-- MathJax -->
    <script type="text/x-mathjax-config">
      MathJax.Hub.Config({
          tex2jax: {
              inlineMath: [ ['$','$'], ["\\(","\\)"]  ],
              processEscapes: true,
              skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
          }
      });

      MathJax.Hub.Queue(function() {
          var all = MathJax.Hub.getAllJax(), i;
          for(i=0; i < all.length; i += 1) {
              all[i].SourceElement().parentNode.className += ' has-jax';
          }
      });

    </script>

    <script src="https://cdn.staticfile.org/mathjax/2.7.6/MathJax.js?config=TeX-MML-AM_CHTML" ></script>

  





</body>
</html>
