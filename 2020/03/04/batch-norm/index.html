<!DOCTYPE html>
<html lang="en | zh-CN | zh-TW">





<head>
  <meta charset="UTF-8">
  <link rel="apple-touch-icon" sizes="76x76" href="/img/apple-touch-icon.png">
  <link rel="icon" type="image/png" href="/img/leaf.jpeg">
  <meta name="viewport"
        content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no, shrink-to-fit=no">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <meta name="description" content="">
  <meta name="author" content="cowarder">
  <meta name="keywords" content="">
  <title>Batch Normalization ~ cowarder</title>

  <link rel="stylesheet" href="/lib/font-awesome/css/all.min.css"  >
<link rel="stylesheet" href="/lib/bootstrap/css/bootstrap.min.css"  >
<link rel="stylesheet" href="/lib/mdbootstrap/css/mdb.min.css"  >
<link rel="stylesheet" href="/lib/github-markdown/github-markdown.min.css"  >
<link rel="stylesheet" href="//at.alicdn.com/t/font_1067060_qzomjdt8bmp.css">


  <link rel="stylesheet" href="/lib/prettify/github-v2.min.css"  >

<link rel="stylesheet" href="/css/main.css"  >


  <link rel="stylesheet" href="/lib/fancybox/jquery.fancybox.min.css"  >


</head>


<body>
  <header style="height: 70vh;">
    <nav id="navbar" class="navbar fixed-top  navbar-expand-lg navbar-dark scrolling-navbar">
  <div class="container">
    <a class="navbar-brand"
       href="/">&nbsp;<strong>cowarder</strong>&nbsp;</a>

    <button id="navbar-toggler-btn" class="navbar-toggler" type="button" data-toggle="collapse"
            data-target="#navbarSupportedContent"
            aria-controls="navbarSupportedContent" aria-expanded="false" aria-label="Toggle navigation">
      <div class="animated-icon"><span></span><span></span><span></span></div>
    </button>

    <!-- Collapsible content -->
    <div class="collapse navbar-collapse" id="navbarSupportedContent">
      <ul class="navbar-nav ml-auto text-center">
        
          
          
          <li class="nav-item">
            <a class="nav-link" href="/">Home</a>
          </li>
        
          
          
          <li class="nav-item">
            <a class="nav-link" href="/archives/">Archives</a>
          </li>
        
          
          
          <li class="nav-item">
            <a class="nav-link" href="/categories/">Categories</a>
          </li>
        
          
          
          <li class="nav-item">
            <a class="nav-link" href="/tags/">Tags</a>
          </li>
        
          
          
          <li class="nav-item">
            <a class="nav-link" href="/about/">About</a>
          </li>
        
        
          <li class="nav-item" id="search-btn">
            <a class="nav-link" data-toggle="modal" data-target="#modalSearch">&nbsp;&nbsp;<i
                class="iconfont icon-search"></i>&nbsp;&nbsp;</a>
          </li>
        
      </ul>
    </div>
  </div>


</nav>

    <div class="view intro-2" id="background"
         style="background: url('/img/sub_main_page.jpg')no-repeat center center;
           background-size: cover;
           background-attachment: fixed;">
      <div class="full-bg-img">
        <div class="mask rgba-black-light flex-center">
          <div class="container text-center white-text fadeInUp">
            <span class="h2" id="subtitle">
              
            </span>

            
              <br>
              
                <p class="mt-3">
                  <i class="fas fa-calendar-alt" aria-hidden="true"></i>&nbsp;
                  Wednesday, March 4th 2020, 10:22 am
                </p>
              

              <p>
                
                  
                  &nbsp;<i class="far fa-chart-bar"></i>
                  <span class="post-count">
                    1.3k 字
                  </span>&nbsp;
                

                
                  
                  &nbsp;<i class="far fa-clock"></i>
                  <span class="post-count">
                      5 分钟
                  </span>&nbsp;
                

                
              </p>
            
          </div>

          
        </div>
      </div>
    </div>
  </header>

  <main>
    
      

<div class="container-fluid">
  <div class="row">
    <div class="d-none d-lg-block col-lg-2"></div>
    <div class="col-lg-8 nopadding-md">
      <div class="py-5 z-depth-3" id="board">
        <div class="post-content mx-auto" id="post">
          <div class="markdown-body">
            <p>这篇文章来回顾一下深度学习网络模型中常见的操作:Batch Normalization。<a href="https://arxiv.org/pdf/1502.03167.pdf" target="_blank" rel="noopener">Batch Normalization</a>是在2015年由Szegedy提出的。主要是解决神经网络中存在的Interval Covariate Shift问题。除了回顾batch normalization有关原理，本文也会介绍几种常见的对于Batch Normalization的改进。</p>
<h4 id="Interval-Covariate-Shift"><a href="#Interval-Covariate-Shift" class="headerlink" title="Interval Covariate Shift"></a>Interval Covariate Shift</h4><p>在Batch Normalization出现之前，训练一个层数较多的神经网络模型是十分困难的，经常出现不收敛的情况，其中重要的原因是，神经网络涉及到很多层的叠加，每一层的参数变化会导致上层输出的改变，经过层层叠加，底层即便是一个微小的波动，也会导致上层输入特征的巨大变化，这就使得上层参数需要不断改变去适应由底层传来的特征，为了使得模型能够收敛，我们需要更加仔细地选择学习率、权重初始化、尽可能选择更好的参数更新策略。</p>
<p>在统计机器学习中一个经典假设是源空间(source domain)和目标空间(target domain)的数据分布是一致的。而covariate shift就是分布不一致假设之下的一个分支问题。概括来讲，对于神经网络的各层输出，由于它们经过了层内操作作用，其分布与各层输入信号分布不同，而且会随着网络深度的增加而增大，这就是interval covariate shift的含义。</p>
<h4 id="BN的具体流程"><a href="#BN的具体流程" class="headerlink" title="BN的具体流程"></a>BN的具体流程</h4><center>
<img src="/2020/03/04/batch-norm/bn.png" srcset="undefined" width="400">
</center>
假设我们每个batch有m个样本，首先我们需要计算m个样本的均值和方差，利用均值和方差进行标准化后，再利用$\gamma$和$\beta$进行缩放和平移，如果仅仅是对每一层进行标准化的话，可能会降低每层网络的表达能力，以sigmoid函数为例，sigmoid函数分为饱和区和非饱和区，而标准化之后的数据会将数据映射到非饱和区，使得其仅仅具有线性表达能力，因此BN中加入了平移和缩放操作来缓解这个问题。

<pre><code class="python">import numpy as np

def Batchnorm(x, gamma, beta, bn_param):

    # x_shape:[B, C, H, W]
    running_mean = bn_param[&#39;running_mean&#39;]
    running_var = bn_param[&#39;running_var&#39;]
    results = 0.
    eps = 1e-5

    x_mean = np.mean(x, axis=(0, 2, 3), keepdims=True)
    x_var = np.var(x, axis=(0, 2, 3), keepdims=True0)
    x_normalized = (x - x_mean) / np.sqrt(x_var + eps)
    results = gamma * x_normalized + beta

    # 因为在测试时是单个图片测试，这里保留训练时的均值和方差，用在后面测试时用
    running_mean = momentum * running_mean + (1 - momentum) * x_mean
    running_var = momentum * running_var + (1 - momentum) * x_var

    bn_param[&#39;running_mean&#39;] = running_mean
    bn_param[&#39;running_var&#39;] = running_var

    return results, bn_param</code></pre>
<h4 id="BN的缺陷"><a href="#BN的缺陷" class="headerlink" title="BN的缺陷"></a>BN的缺陷</h4><p>BN依赖于batch大小的选择，如果太小会造成模型的不稳定，实验表明，ResNet在ImageNet数据集上进行训练，batch size从16降到8之后性能会有明显的下降，因此BN在以下两种情况下不适应。</p>
<p>1.batch非常小。有时受限于计算资源，不得不选择一个较小的batch size，这时使用BN可能不会造成性能提升。</p>
<p>2.RNN。由于RNN是一个动态的网络结构，同一个batch中的样本长短不一，因此每个batch的统计量不稳定，使得BN无法正确使用。</p>
<h4 id="BN的改进"><a href="#BN的改进" class="headerlink" title="BN的改进"></a>BN的改进</h4><h5 id="Layer-Normalization"><a href="#Layer-Normalization" class="headerlink" title="Layer Normalization"></a><a href="https://arxiv.org/pdf/1607.06450v1.pdf" target="_blank" rel="noopener">Layer Normalization</a></h5><p>Layer Normalization就是针对BN的不足提出的，BN可以看作是一种纵向的归一化，而LN可以看作是一种横向的归一化，LN针对单个训练样本进行训练，不依赖于其他数据，因此可以避免BN受batch size影响的情况出现，可以应用于小batch数据上面。</p>
<center>
<img src="/2020/03/04/batch-norm/layer.png" srcset="undefined">
</center>

<p>对于四维图像数据(B, C, H, W)来说，BN进行归一化的时候使用的均值和方差形状都为(1, C, 1, 1)，也就是说每一个channel保留一个值，在B、H、W上面求均值。而对于LN来讲，均值和方差形状为(B, 1, 1, 1)，即batch中的每个样本都有一个固定的值来对其进行归一化，在C、H、W、上面求均值。</p>
<pre><code class="python">def Layernorm(x, gamma, beta):

    # x_shape:[B, C, H, W]
    results = 0.
    eps = 1e-5

    x_mean = np.mean(x, axis=(1, 2, 3), keepdims=True)
    x_var = np.var(x, axis=(1, 2, 3), keepdims=True0)
    x_normalized = (x - x_mean) / np.sqrt(x_var + eps)
    results = gamma * x_normalized + beta
    return results</code></pre>
<h5 id="Instance-Normalization"><a href="#Instance-Normalization" class="headerlink" title="Instance Normalization"></a><a href="https://arxiv.org/pdf/1607.08022.pdf" target="_blank" rel="noopener">Instance Normalization</a></h5><p>IN最初应用于图像的风格迁移，作者发现，在生成模型中，feature map的各个channel的均值和方差会影响最终生成图像的风格，因此需要对HW进行归一化，加速模型收敛，并且保持每个样本之间的独立性，IN同样也是不受batch size影响的，均值和方差为(B, C, 1, 1)</p>
<pre><code class="python">def Instancenorm(x, gamma, beta):

    # x_shape:[B, C, H, W]
    results = 0.
    eps = 1e-5

    x_mean = np.mean(x, axis=(2, 3), keepdims=True)
    x_var = np.var(x, axis=(2, 3), keepdims=True0)
    x_normalized = (x - x_mean) / np.sqrt(x_var + eps)
    results = gamma * x_normalized + beta
    return results</code></pre>
<h5 id="Group-Normalization"><a href="#Group-Normalization" class="headerlink" title="Group Normalization"></a><a href="https://arxiv.org/pdf/1803.08494.pdf" target="_blank" rel="noopener">Group Normalization</a></h5><center>
<img src="/2020/03/04/batch-norm/gn.png" srcset="undefined">
</center>

<p>主要是针对BN中小batch效果差的问题，GN将channel方向分group，每个group内做归一化，计算(C//G)*H*W的均值，同样的，GN与batch size无关，不受约束。</p>
<pre><code class="python">def GroupNorm(x, gamma, beta, G=16):

    # x_shape:[B, C, H, W]
    results = 0.
    eps = 1e-5
    x = np.reshape(x, (x.shape[0], G, x.shape[1]/16, x.shape[2], x.shape[3]))

    x_mean = np.mean(x, axis=(2, 3, 4), keepdims=True)
    x_var = np.var(x, axis=(2, 3, 4), keepdims=True0)
    x_normalized = (x - x_mean) / np.sqrt(x_var + eps)
    results = gamma * x_normalized + beta
    return results</code></pre>

            <hr>
          </div>
          <br>
          <div>
            <p>
            
            
              <span>
                <i class="iconfont icon-tag"></i>
                
                  <a class="hover-with-bg" href="/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0">深度学习</a>
                
              </span>
            
            </p>
            
              <p class="note note-warning">本博客所有文章除特别声明外，均采用 <a href="https://zh.wikipedia.org/wiki/Wikipedia:CC_BY-SA_3.0%E5%8D%8F%E8%AE%AE%E6%96%87%E6%9C%AC" target="_blank" rel="nofollow noopener noopener">CC BY-SA 3.0协议</a> 。转载请注明出处！</p>
            
          </div>
        </div>
      </div>
    </div>
    <div class="d-none d-lg-block col-lg-2 toc-container">
      
  <div id="toc">
    <p class="h4"><i class="far fa-list-alt"></i>&nbsp;目录</p>
    <div id="tocbot"></div>
  </div>

    </div>
  </div>
</div>

<!-- custom -->


<!-- Comments -->
<div class="col-lg-7 mx-auto nopadding-md">
  <div class="container comments mx-auto" id="comments">
    
  </div>
</div>

    
  </main>

  
    <a class="z-depth-1" id="scroll-top-button" href="#" role="button">
      <i class="fa fa-chevron-up scroll-top-arrow" aria-hidden="true"></i>
    </a>
  

  
    <div class="modal fade" id="modalSearch" tabindex="-1" role="dialog" aria-labelledby="ModalLabel"
     aria-hidden="true">
  <div class="modal-dialog modal-dialog-scrollable modal-lg" role="document">
    <div class="modal-content">
      <div class="modal-header text-center">
        <h4 class="modal-title w-100 font-weight-bold">搜索</h4>
        <button type="button" id="local-search-close" class="close" data-dismiss="modal" aria-label="Close">
          <span aria-hidden="true">&times;</span>
        </button>
      </div>
      <div class="modal-body mx-3">
        <div class="md-form mb-5">
          <input type="text" id="local-search-input" class="form-control validate">
          <label data-error="x" data-success="v"
                 for="local-search-input">关键词</label>
        </div>
        <div class="list-group" id="local-search-result"></div>
      </div>
    </div>
  </div>
</div>
  

  <footer class="mt-5">
  <div class="text-center py-3">
    <a href="https://hexo.io" target="_blank" rel="nofollow noopener"><b>Hexo</b></a>
    <i class="iconfont icon-love"></i>
    <a href="https://github.com/fluid-dev/hexo-theme-fluid" target="_blank" rel="nofollow noopener"> <b>Fluid</b></a>
    <br>

    
  
  
  <br>



    

  </div>
</footer>

<!-- SCRIPTS -->
<script src="/lib/jquery/jquery.min.js" ></script>
<script src="/lib/popper/popper.min.js" ></script>
<script src="/lib/bootstrap/js/bootstrap.min.js" ></script>
<script src="/lib/mdbootstrap/js/mdb.min.js" ></script>
<script src="/js/main.js" ></script>


  <script src="/js/lazyload.js" ></script>



  
    <script src="/lib/tocbot/tocbot.min.js" ></script>
  
  <script src="/js/post.js" ></script>



  <script src="/lib/smooth-scroll/smooth-scroll.min.js" ></script>



  <script async src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js" ></script>


<!-- Plugins -->


  

  

  

  

  




  <script src="/lib/prettify/prettify.min.js" ></script>
  <script>
    $(document).ready(function () {
      $('pre').addClass('prettyprint  linenums');
      prettyPrint();
    })
  </script>



  <script src="/lib/typed/typed.min.js" ></script>
  <script>
    var typed = new Typed('#subtitle', {
      strings: [
        '  ',
        "Batch Normalization&nbsp;",
      ],
      cursorChar: "_",
      typeSpeed: 70,
      loop: false,
    });
    typed.stop();
    $(document).ready(function () {
      $(".typed-cursor").addClass("h2");
      typed.start();
    });
  </script>



  <script src="/lib/anchor/anchor.min.js" ></script>
  <script>
    anchors.options = {
      placement: "right",
      visible: "false",
      
    };
    var el = "h1,h2,h3,h4,h5,h6".split(",");
    var res = [];
    for (item of el) {
      res.push(".markdown-body > " + item)
    }
    anchors.add(res.join(", "))
  </script>



  <script src="/js/local-search.js" ></script>
  <script>
    var path = "/local-search.xml";
    var inputArea = document.querySelector("#local-search-input");
    inputArea.onclick = function () {
      getSearchFile(path);
      this.onclick = null
    }
  </script>



  <script src="/lib/fancybox/jquery.fancybox.min.js" ></script>
  <script>
    $("#post img:not(.no-zoom img, img[no-zoom])").each(
      function () {
        var element = document.createElement("a");
        $(element).attr("data-fancybox", "images");
        $(element).attr("href", $(this).attr("src"));
        $(this).wrap(element);
      }
    );
  </script>



  

  
    <!-- MathJax -->
    <script type="text/x-mathjax-config">
      MathJax.Hub.Config({
          tex2jax: {
              inlineMath: [ ['$','$'], ["\\(","\\)"]  ],
              processEscapes: true,
              skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
          }
      });

      MathJax.Hub.Queue(function() {
          var all = MathJax.Hub.getAllJax(), i;
          for(i=0; i < all.length; i += 1) {
              all[i].SourceElement().parentNode.className += ' has-jax';
          }
      });

    </script>

    <script src="https://cdn.staticfile.org/mathjax/2.7.6/MathJax.js?config=TeX-MML-AM_CHTML" ></script>

  





</body>
</html>
