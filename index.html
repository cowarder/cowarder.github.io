<!DOCTYPE html>
<html lang="en | zh-CN | zh-TW">





<head>
  <meta charset="UTF-8">
  <link rel="apple-touch-icon" sizes="76x76" href="/img/apple-touch-icon.png">
  <link rel="icon" type="image/png" href="/img/leaf.jpeg">
  <meta name="viewport"
        content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no, shrink-to-fit=no">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <meta name="description" content="">
  <meta name="author" content="cowarder">
  <meta name="keywords" content="">
  <title>cowarder</title>

  <link rel="stylesheet" href="/lib/font-awesome/css/all.min.css"  >
<link rel="stylesheet" href="/lib/bootstrap/css/bootstrap.min.css"  >
<link rel="stylesheet" href="/lib/mdbootstrap/css/mdb.min.css"  >
<link rel="stylesheet" href="/lib/github-markdown/github-markdown.min.css"  >
<link rel="stylesheet" href="//at.alicdn.com/t/font_1067060_qzomjdt8bmp.css">


  <link rel="stylesheet" href="/lib/prettify/github-v2.min.css"  >

<link rel="stylesheet" href="/css/main.css"  >


  <link rel="stylesheet" href="/lib/fancybox/jquery.fancybox.min.css"  >


</head>


<body>
  <header style="height: 100vh;">
    <nav id="navbar" class="navbar fixed-top  navbar-expand-lg navbar-dark scrolling-navbar">
  <div class="container">
    <a class="navbar-brand"
       href="/">&nbsp;<strong>cowarder</strong>&nbsp;</a>

    <button id="navbar-toggler-btn" class="navbar-toggler" type="button" data-toggle="collapse"
            data-target="#navbarSupportedContent"
            aria-controls="navbarSupportedContent" aria-expanded="false" aria-label="Toggle navigation">
      <div class="animated-icon"><span></span><span></span><span></span></div>
    </button>

    <!-- Collapsible content -->
    <div class="collapse navbar-collapse" id="navbarSupportedContent">
      <ul class="navbar-nav ml-auto text-center">
        
          
          
          <li class="nav-item">
            <a class="nav-link" href="/">Home</a>
          </li>
        
          
          
          <li class="nav-item">
            <a class="nav-link" href="/archives/">Archives</a>
          </li>
        
          
          
          <li class="nav-item">
            <a class="nav-link" href="/tags/">Tags</a>
          </li>
        
          
          
          <li class="nav-item">
            <a class="nav-link" href="/about/">About</a>
          </li>
        
        
          <li class="nav-item" id="search-btn">
            <a class="nav-link" data-toggle="modal" data-target="#modalSearch">&nbsp;&nbsp;<i
                class="iconfont icon-search"></i>&nbsp;&nbsp;</a>
          </li>
        
      </ul>
    </div>
  </div>


</nav>

    <div class="view intro-2" id="background"
         style="background: url('/img/main_page.jpg')no-repeat center center;
           background-size: cover;
           background-attachment: fixed;">
      <div class="full-bg-img">
        <div class="mask rgba-black-light flex-center">
          <div class="container text-center white-text fadeInUp">
            <span class="h2" id="subtitle">
              
            </span>

            
          </div>

          
            <div class="scroll-down-bar">
              <i class="fas fa-angle-down scroll-down-arrow"></i>
            </div>
          
        </div>
      </div>
    </div>
  </header>

  <main>
    
      <div class="container nopadding-md">
        <div class="py-5 z-depth-3" id="board">
          
          <div class="container">
            <div class="row">
              <div class="col-12 col-md-10 m-auto">
                


  <div class="row mb-4 mx-auto">
    
    
      <div class="col-12 col-md-4 m-auto">
        <a href="/2021/02/22/docker/" target="_self">
          <img src="/img/docker.png" srcset="undefined" alt="docker简介及随手查" class="img-fluid rounded z-depth-3 index-thumbnails">
        </a>
      </div>
    
    <div class="col-12 col-md-8 m-auto">
      <a href="/2021/02/22/docker/">
        <p class="h4 index-header">docker简介及随手查</p>
        
        
          
        
        <div class="index-excerpt" >
          <div class="index-text mb-1">环境配置问题程序员经常可以听到的一句话是：“代码明明在我电脑上面能跑的啊，怎么到你这就不行了？肯定是你电脑问题（不是）”。听上去是一个调侃，其实确实是经常遇见的问题，而这个问题出现的本质原因是由环境配置引起的。代码运行需要依赖于环境，比如操作系统的设置，各种库和组件的配置，可能还涉及到很多的环境变量，而这些东西都是定制化的，当我们换一台机器的时候，就需要重新再配置一次，可以预见，这个过程需要做许多重复性的工作，耗费大量精力，那么自然就可以想到，我们在拷贝一份代码或者运行一个软件的时候，能否同时将原市的环境也囊括进来？
虚拟机虚拟机是带着环境安装的一种解决方案。虚拟机是一种在操作系统里面运行的操作系统，对于底层系统来讲，虚拟机是一个普通文件，但是虚拟机会占用更多的资源，独占一部分内存和硬盘空间，虚拟机运行的时候，其他程序无法使用这些资源，即便是虚拟机里面的程序需要占用的内存很少，但是虚拟机仍然需要很大一部分资源才能够运行。而且虚拟机是操作系统级别的，启动起来非常慢。
Linux容器由于虚拟机存在的诸多问题，Linux发展了另外一种虚拟化技术：linux容器。linux容器不是一个完整的操</div>
        </div>
      </a>

      <div>
        
          <i class="iconfont icon-riqi2"></i>&nbsp;2021-02-22&nbsp;&nbsp;
        
        
        
          <i class="iconfont icon-tag"></i>
          
            <a href="/tags/docker">docker</a>&nbsp;
          
        
      </div>
    </div>
  </div>

  <div class="row mb-4 mx-auto">
    
    
      <div class="col-12 col-md-4 m-auto">
        <a href="/2020/12/07/3d-detection/" target="_self">
          <img src="/img/pcd.png" srcset="undefined" alt="3D目标检测算法调研" class="img-fluid rounded z-depth-3 index-thumbnails">
        </a>
      </div>
    
    <div class="col-12 col-md-8 m-auto">
      <a href="/2020/12/07/3d-detection/">
        <p class="h4 index-header">3D目标检测算法调研</p>
        
        
          
        
        <div class="index-excerpt" >
          <div class="index-text mb-1">刚刚来到百度实习，方向是3D目标检测，前期工作是做算法调研，撰写本篇博客略作记录  
目前，2D目标检测算法已经发展的比较成熟，但是在无人驾驶、机器人、增强现实的应用场景下，普通的2D检测并不能提供感知环境所需要的全部信息，2D检测仅能提供目标物体在二维图片中的位置和对应类别的置信度，但是在真实的三维世界中，物体都是有三维形状的，大部分应用都需要有目标物体的长宽高还有偏转角度等信息。目前的3D目标检测正处于高速发展时期，目前主要是综合利用单目相机、双目相机、多线激光雷达来进行3D目标检测，从成本上来讲，激光雷达&gt;双目相机&gt;单目相机，从目前的准确率上来讲，激光雷达&gt;双目相机&gt;单目相机。但是随着激光雷达的不断产业化发展，成本在不断降低，目前也出现了一些使用单目相机加线数较少的激光雷达进行综合使用的技术方案  
因为在百度实习所做的方向是基于激光点云数据的3D目标检测，因此主要对基于点云的方法进行探讨。从点云数据表示的角度来讲，我们可以将现有的主流检测方法分为两类：一种是voxel-based的方法(将不规则的点云数据转换为规则数据)，另外一种就是point-base</div>
        </div>
      </a>

      <div>
        
          <i class="iconfont icon-riqi2"></i>&nbsp;2020-12-07&nbsp;&nbsp;
        
        
        
          <i class="iconfont icon-tag"></i>
          
            <a href="/tags/%E5%AE%9E%E4%B9%A0">实习</a>&nbsp;
          
        
      </div>
    </div>
  </div>

  <div class="row mb-4 mx-auto">
    
    
      <div class="col-12 col-md-4 m-auto">
        <a href="/2020/10/22/tsm/" target="_self">
          <img src="/img/tsm.png" srcset="undefined" alt="论文阅读《Temporal Shift Module for Efficient Video Understanding》" class="img-fluid rounded z-depth-3 index-thumbnails">
        </a>
      </div>
    
    <div class="col-12 col-md-8 m-auto">
      <a href="/2020/10/22/tsm/">
        <p class="h4 index-header">论文阅读《Temporal Shift Module for Efficient Video Understanding》</p>
        
        
          
        
        <div class="index-excerpt" >
          <div class="index-text mb-1">Abstract视频理解领域，高准确率和低计算成本的权衡一直是一个十分重要的问题。传统的2D卷积计算量很小，但是只能捕捉图像中的空间信息，无法捕捉帧与帧之间的时序信息。基于3D卷积的方法虽然效果很好，但是计算成本太高，实际部署困难。这篇文章中，我们提出了一种泛化性强、效率高的模块(Temporal Shift Module)，能够同时实现高效和高精度，能够实现3D卷积精度的基础上，仍然保持2D卷积的计算成本。TSM在时间维度上面移动了部分通道，便于在相邻帧图像之间交换信息。TSM模块可以插入2D卷积模型中，在不增加任何计算成本的条件下实现时间建模。我们还将TSM应用在在线任务中，实现了实时低延迟的在线视频识别和视频对象检测。TSM准确而有效，在Something-Something数据集榜单上面排行第一，在Galaxy Note8手机上面，实现了35ms低延迟的在线视频识别。代码可以在这里找到  
TSM模块TSM通过沿着时间维度移动特征图通道来执行有效的时间建模。相较于2D卷积，并没有增加计算量，但是TSM结构具有强大的时间建模能力。TSM能够有效支持在线和离线视频分类任务，双向TS</div>
        </div>
      </a>

      <div>
        
          <i class="iconfont icon-riqi2"></i>&nbsp;2020-10-22&nbsp;&nbsp;
        
        
        
          <i class="iconfont icon-tag"></i>
          
            <a href="/tags/%E8%AE%BA%E6%96%87">论文</a>&nbsp;
          
        
      </div>
    </div>
  </div>

  <div class="row mb-4 mx-auto">
    
    
      <div class="col-12 col-md-4 m-auto">
        <a href="/2020/10/05/pingan/" target="_self">
          <img src="/img/pingan.jpg" srcset="undefined" alt="平安科技实习总结" class="img-fluid rounded z-depth-3 index-thumbnails">
        </a>
      </div>
    
    <div class="col-12 col-md-8 m-auto">
      <a href="/2020/10/05/pingan/">
        <p class="h4 index-header">平安科技实习总结</p>
        
        
          
        
        <div class="index-excerpt" >
          <div class="index-text mb-1">今年7月份到9月份在平安科技(上海)实习了一段时间，岗位是人脸识别算法组算法工程师，主要负责采用深度学习进行视频流的唇语识别。平安科技不愧是保险公司，就是有钱，当时组里有四个实习生，我做唇语识别，另外三个人做GAN、声形同步、以及3D目标检测，平均每个人有一台8卡Tesla v100可以用，有充足计算资源自己折腾实验  
当时我负责的研究内容是读验证码唇语识别，给定的数据是公司的内部数据，每个样本是一个短视频，里面显示的是不同的人读取数字，实习期间针对这个任务做了一系列的改进 。整体大致流程是：输入视频数据-&gt;提取音频-&gt;根据音频截取视频中间说话人的部分-&gt;从截取视频中抽取固定帧图像-&gt;训练  
1.数据分析前期拿到数据首先做了初步的分析，数据比较脏，存在诸多问题：

(1) 噪音较多。背景音比较嘈杂
(2) 方言。导致同一验证码唇形变化不一致
(3) 重复读。一个验证码有的人会读多次
(4) 截断。并没有完整截取视频片段
(5) 唇动不明显。这种情形更多是个人习惯导致

噪音问题会导致我们在截取视频前后片段时的不准确，从而导致采样图片帧出现较大误差，如何从视频</div>
        </div>
      </a>

      <div>
        
          <i class="iconfont icon-riqi2"></i>&nbsp;2020-10-05&nbsp;&nbsp;
        
        
        
          <i class="iconfont icon-tag"></i>
          
            <a href="/tags/%E5%AE%9E%E4%B9%A0">实习</a>&nbsp;
          
        
      </div>
    </div>
  </div>

  <div class="row mb-4 mx-auto">
    
    
      <div class="col-12 col-md-4 m-auto">
        <a href="/2020/09/28/mldl/" target="_self">
          <img src="/img/mldl.png" srcset="undefined" alt="机器学习与深度学习指北" class="img-fluid rounded z-depth-3 index-thumbnails">
        </a>
      </div>
    
    <div class="col-12 col-md-8 m-auto">
      <a href="/2020/09/28/mldl/">
        <p class="h4 index-header">机器学习与深度学习指北</p>
        
        
          
        
        <div class="index-excerpt" >
          <div class="index-text mb-1">这篇文章是我之前写给同实验室的师弟师妹们看的，没有外传过，如果机器学习基础不牢固，就直接搞深度学习，我觉得不太可取，但是问了问他们又没有一个明确的学习计划，为了能让他们尽量少走弯路，尽快搞定深度学习&amp;机器学习的基础，写了这篇文章。这篇文章主要是记录我的学习过程，主观性可能比较强，仅供参考，学不好本人概不负责(QAQ)
机器学习&amp;深度学习指北前言:本文将从作者学习经历出发，提炼出一条学习路线。网上的相关学习资料层出不穷，存在大量低质资源(各种教授、高级工程师出的 网课、书籍)，且存在很大程度上面的内容交叉，作者在学习的过程中也走过很多弯路，因 此本文的主要目的是让初学者对机器学习、深度学习迅速构建起一个知识脉络，避免走太多 的弯路，浪费宝贵时间。首先声明本文可能具有较大的主观性，因此内容仅做参考。
首先提出两点误区，1)上来就搞深度学习。深度学习只是机器学习的一小部分，应该 是对机器学习有了一定的基础之后，再去研究深度学习，没有机器学习知识储备就去搞深度 学习是不可取的，很容易成为一个调参工程师。2)重理论，轻实践。很多人只看书，把书 里面的公式推一推，就以为自己已经掌握</div>
        </div>
      </a>

      <div>
        
          <i class="iconfont icon-riqi2"></i>&nbsp;2020-09-28&nbsp;&nbsp;
        
        
        
          <i class="iconfont icon-tag"></i>
          
            <a href="/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0">深度学习</a>&nbsp;
          
        
      </div>
    </div>
  </div>

  <div class="row mb-4 mx-auto">
    
    
      <div class="col-12 col-md-4 m-auto">
        <a href="/2020/09/08/mianshi/" target="_self">
          <img src="/img/moyu.png" srcset="undefined" alt="2020秋招常见视觉面试题整理" class="img-fluid rounded z-depth-3 index-thumbnails">
        </a>
      </div>
    
    <div class="col-12 col-md-8 m-auto">
      <a href="/2020/09/08/mianshi/">
        <p class="h4 index-header">2020秋招常见视觉面试题整理</p>
        
        
          
        
        <div class="index-excerpt" >
          <div class="index-text mb-1">2020秋招，牛客上面面试问到的问题整理，太过简单的没有记录，太偏的没有记录，主要涵盖深度学习、机器学习、目标检测
1.介绍一下faster rcnn
2.faster rcnn如何进行feature map选取的
3.faster rcnn中的anchor作用，怎么进行不同box提取
4.yolo和faster rcnn区别
5.有哪些激活函数，有什么用，各自的特点，改进了什么？
6.池化怎么进行反向传播
7.介绍逻辑回归以及其损失函数，LR推倒
8.如何解决类别不平衡问题
9.ResNet的特点
10.为什么使用1x1卷积？哪些情况下使用1x1卷积？
11.SVM原理，具有哪些核函数，软间隔是怎么做的
12.L1正则化和L2正则化区别，为什么L1能够产生稀疏性
13.如何解决前景背景数量不均衡
14.mobilenetv1和v2的区别
15.训练过程中loss一直无法收敛，可能的情况
16.为什么卷积核都是基数（padding角度）
17.双线性插值
18.inception如何减少计算量
19.反卷积操作
20.SSD里面的OHEM，正负样本为什么是1:3
21.SSD缺点，特点</div>
        </div>
      </a>

      <div>
        
          <i class="iconfont icon-riqi2"></i>&nbsp;2020-09-08&nbsp;&nbsp;
        
        
        
          <i class="iconfont icon-tag"></i>
          
            <a href="/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0">深度学习</a>&nbsp;
          
        
      </div>
    </div>
  </div>

  <div class="row mb-4 mx-auto">
    
    
      <div class="col-12 col-md-4 m-auto">
        <a href="/2020/08/20/yolov4/" target="_self">
          <img src="/img/yolov4.png" srcset="undefined" alt="YOLOv4" class="img-fluid rounded z-depth-3 index-thumbnails">
        </a>
      </div>
    
    <div class="col-12 col-md-8 m-auto">
      <a href="/2020/08/20/yolov4/">
        <p class="h4 index-header">YOLOv4</p>
        
        
          
        
        <div class="index-excerpt" >
          <div class="index-text mb-1">YOLOv4: Optimal Speed and Accuracy of Object Detection.
arxiv: https://arxiv.org/abs/2004.10934
github: https://github.com/AlexeyAB/darknet
第一版YOLO文章的发布，标志着基于深度学习的单阶段目标检测算法的开端，随后相继出现了YOLOv2，YOLOv3等家族系列文章。最近，YOLOv4正式发表，文章的主要内容是结合大量前人的工作，进行了大量的实验，并在此基础上面进行了一定的创新，在COCO数据集上面实现了43.5%的mAP，并且保持了65FPS的速度，实现了速度和精度的平衡
文章中将前人在目标检测领域的工作大致分为两类：bag of freebies和bag of specials， 前者主要指的是在训练过程中应用的技巧，这种技巧不会显著增强模型测试阶段的速度和模型复杂度负担，只体现在训练阶段，主要就是数据增强操作。后者会稍微增加模型复杂度和时间开销，但是对精度会有更大的提升，例如一些后处理操作(NMS)
本文主要对YOLOv4中提到的创新进行分析</div>
        </div>
      </a>

      <div>
        
          <i class="iconfont icon-riqi2"></i>&nbsp;2020-08-20&nbsp;&nbsp;
        
        
        
          <i class="iconfont icon-tag"></i>
          
            <a href="/tags/object%20detection">object detection</a>&nbsp;
          
        
      </div>
    </div>
  </div>

  <div class="row mb-4 mx-auto">
    
    
      <div class="col-12 col-md-4 m-auto">
        <a href="/2020/07/17/video-class/" target="_self">
          <img src="/img/video_class.jpg" srcset="undefined" alt="基于深度学习的视频分类" class="img-fluid rounded z-depth-3 index-thumbnails">
        </a>
      </div>
    
    <div class="col-12 col-md-8 m-auto">
      <a href="/2020/07/17/video-class/">
        <p class="h4 index-header">基于深度学习的视频分类</p>
        
        
          
        
        <div class="index-excerpt" >
          <div class="index-text mb-1">利用深度学习进行图像分类发展到目前已经日趋成熟，在ImageNet数据集上面的准确率已经超过人类水平，但是视频分类仍然处在一个萌芽时期，视频分类技术并没有像二维图像分类那样成熟 
视频分类的难点视频分类相较于图像分类，主要有两个难点： 
1.如何有效利用时序信息
深度学习利用卷积处理二维图像，能够有效利用图像中物体的位置、角度、色彩等信息，但是视频数据中会多出一维时间信息，而这一维中会蕴含大量有效信息，例如击球场景下，前一帧图像中击球动作发生，后一帧球轨迹改变，这里面就蕴含直接的因果关系，但这是时间维度上面的，传统的二维卷积没有办法学习和利用到这种信息

2.如何减少运算量
可以将视频视为在时间维度上面离散的二维图像，利用深度学习做视频分类最直接的方法就是利用3维卷积，相当于将原来的2维卷积核扩展为3维，这样看似简单的思想，带来的计算量的增加却是非常可怖的，因此如何减少视频分类任务中所需的计算量也是至关重要的一点

主流方法目前基于深度学习的视频分类任务主要有两个大的方向：
1.基于3D卷积的方法
将原有的(a, b, c)大小的卷积核转换为(a, b, c, n)大小，这样能够利用时</div>
        </div>
      </a>

      <div>
        
          <i class="iconfont icon-riqi2"></i>&nbsp;2020-07-17&nbsp;&nbsp;
        
        
        
          <i class="iconfont icon-tag"></i>
          
            <a href="/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0">深度学习</a>&nbsp;
          
        
      </div>
    </div>
  </div>

  <div class="row mb-4 mx-auto">
    
    
      <div class="col-12 col-md-4 m-auto">
        <a href="/2020/05/01/one-stage-detection/" target="_self">
          <img src="/img/one-stage.png" srcset="undefined" alt="单阶段目标检测算法" class="img-fluid rounded z-depth-3 index-thumbnails">
        </a>
      </div>
    
    <div class="col-12 col-md-8 m-auto">
      <a href="/2020/05/01/one-stage-detection/">
        <p class="h4 index-header">单阶段目标检测算法</p>
        
        
          
        
        <div class="index-excerpt" >
          <div class="index-text mb-1">上一篇文章中，我们详细介绍了几种常见的两阶段目标检测算法，两阶段目标检测算法由于proposal的产生，在精度上面更具优势，但是单阶段目标检测算法在速度上面更快
本文将整理几种常见的单阶段目标检测算法(YOLO, YOLOv2, YOLOv3, SSD, RetinaNet)，主要从解决的问题、创新点、算法具体流程、仍然存在的问题等方面进行阐述
YOLO时间：2015



解决的问题两阶段目标检测中检测速度太慢的问题
创新点YOLO是深度学习目标检测领域第一个单阶段目标检测算法，在Pascal VOC2007数据集上面实现了52.7%的mAP，155fps。作者完全舍弃了之前存在的”proposal + classification”的固有检测模式，将检测问题由一个分类问题转换为一个回归问题
算法流程1.将输入图片resize到$448\times 448$
2.通过CNN将输入图像分割成$S\times S$的网格，每个网格负责去检测中心点落在其中的目标
3.每个网格需要预测B个边界框，每个边界框具有位置以及置信度信息，每个网格同时需要预测一个类别信息，最终$S\times S\t</div>
        </div>
      </a>

      <div>
        
          <i class="iconfont icon-riqi2"></i>&nbsp;2020-05-01&nbsp;&nbsp;
        
        
        
          <i class="iconfont icon-tag"></i>
          
            <a href="/tags/object%20detection">object detection</a>&nbsp;
          
        
      </div>
    </div>
  </div>

  <div class="row mb-4 mx-auto">
    
    
      <div class="col-12 col-md-4 m-auto">
        <a href="/2020/04/15/small-od/" target="_self">
          <img src="/img/sod.jpeg" srcset="undefined" alt="小目标检测(Small Object Detection)" class="img-fluid rounded z-depth-3 index-thumbnails">
        </a>
      </div>
    
    <div class="col-12 col-md-8 m-auto">
      <a href="/2020/04/15/small-od/">
        <p class="h4 index-header">小目标检测(Small Object Detection)</p>
        
        
          
        
        <div class="index-excerpt" >
          <div class="index-text mb-1">现今存在的通用目标检测方法大多数在一般大小的物体上面检测效果较好，但是针对小物体的检测效果较差。目前的检测方法基本基于深度学习，而神经网络是由逐层卷积网络组成的，我们以一个常用的分类神经网络举例。


  
    Generic image classification baseline.
  


网络中包含有一系列的卷积+pooling层，在检测网络中，如YOLO、SSD、Faster R-CNN等中也会大量使用这种类似结构，我们利用神经网络将600x600的输入转化为30x30的特征。但是这样的网络结果造成的一个非常直观的问题，如果在原始(600x600)图片中很小的物体，经过卷积映射为低维特征(30x30)之后，小物体特征几乎可以忽略不计，甚至完全消失，在训练过程中，网络在靠后的特征层中就失去了小物体的监督信息，因此就会造成检测性能的下降。
本文旨在总结几种常见的解决小物体检测的方法，大体可以分为四类：多尺度特征学习、数据增强、采用训练策略、基于GAN的检测。
1.多尺度特征学习如何去处理特征尺度问题对于小物体检测十分重要，大体可以分为7类：特征图像金字塔、单尺度特征、金字塔</div>
        </div>
      </a>

      <div>
        
          <i class="iconfont icon-riqi2"></i>&nbsp;2020-04-15&nbsp;&nbsp;
        
        
        
          <i class="iconfont icon-tag"></i>
          
            <a href="/tags/object%20detection">object detection</a>&nbsp;
          
        
      </div>
    </div>
  </div>



  <nav aria-label="index posts navigation">
    <span class="pagination pg-blue justify-content-center mt-5" id="pagination">
      <span class="page-number current">1</span><a class="page-number" href="/page/2/">2</a><a class="page-number" href="/page/3/">3</a><a class="extend next" rel="next" href="/page/2/"><i class="fas fa-angle-double-right"></i></a>
    </span>
  </nav>
  
  <script>
    for (ele of document.getElementById("pagination").getElementsByClassName("page-number")) {
      ele.href += '#board';
    }
  </script>



              </div>
            </div>
          </div>
        </div>
      </div>
    
  </main>

  
    <a class="z-depth-1" id="scroll-top-button" href="#" role="button">
      <i class="fa fa-chevron-up scroll-top-arrow" aria-hidden="true"></i>
    </a>
  

  
    <div class="modal fade" id="modalSearch" tabindex="-1" role="dialog" aria-labelledby="ModalLabel"
     aria-hidden="true">
  <div class="modal-dialog modal-dialog-scrollable modal-lg" role="document">
    <div class="modal-content">
      <div class="modal-header text-center">
        <h4 class="modal-title w-100 font-weight-bold">搜索</h4>
        <button type="button" id="local-search-close" class="close" data-dismiss="modal" aria-label="Close">
          <span aria-hidden="true">&times;</span>
        </button>
      </div>
      <div class="modal-body mx-3">
        <div class="md-form mb-5">
          <input type="text" id="local-search-input" class="form-control validate">
          <label data-error="x" data-success="v"
                 for="local-search-input">关键词</label>
        </div>
        <div class="list-group" id="local-search-result"></div>
      </div>
    </div>
  </div>
</div>
  

  <footer class="mt-5">
  <div class="text-center py-3">
    <a href="https://hexo.io" target="_blank" rel="nofollow noopener"><b>Hexo</b></a>
    <i class="iconfont icon-love"></i>
    <a href="https://github.com/fluid-dev/hexo-theme-fluid" target="_blank" rel="nofollow noopener"> <b>Fluid</b></a>
    <br>

    
  
  
  <br>



    

  </div>
</footer>

<!-- SCRIPTS -->
<script src="/lib/jquery/jquery.min.js" ></script>
<script src="/lib/popper/popper.min.js" ></script>
<script src="/lib/bootstrap/js/bootstrap.min.js" ></script>
<script src="/lib/mdbootstrap/js/mdb.min.js" ></script>
<script src="/js/main.js" ></script>


  <script src="/js/lazyload.js" ></script>





  <script src="/lib/smooth-scroll/smooth-scroll.min.js" ></script>



  <script async src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js" ></script>


<!-- Plugins -->


  

  

  

  

  




  <script src="/lib/prettify/prettify.min.js" ></script>
  <script>
    $(document).ready(function () {
      $('pre').addClass('prettyprint  linenums');
      prettyPrint();
    })
  </script>



  <script src="/lib/typed/typed.min.js" ></script>
  <script>
    var typed = new Typed('#subtitle', {
      strings: [
        '  ',
        "生活就是一个缓慢受锤的过程&nbsp;",
      ],
      cursorChar: "_",
      typeSpeed: 70,
      loop: false,
    });
    typed.stop();
    $(document).ready(function () {
      $(".typed-cursor").addClass("h2");
      typed.start();
    });
  </script>



  <script src="/lib/anchor/anchor.min.js" ></script>
  <script>
    anchors.options = {
      placement: "right",
      visible: "false",
      
    };
    var el = "h1,h2,h3,h4,h5,h6".split(",");
    var res = [];
    for (item of el) {
      res.push(".markdown-body > " + item)
    }
    anchors.add(res.join(", "))
  </script>



  <script src="/js/local-search.js" ></script>
  <script>
    var path = "/local-search.xml";
    var inputArea = document.querySelector("#local-search-input");
    inputArea.onclick = function () {
      getSearchFile(path);
      this.onclick = null
    }
  </script>



  <script src="/lib/fancybox/jquery.fancybox.min.js" ></script>
  <script>
    $("#post img:not(.no-zoom img, img[no-zoom])").each(
      function () {
        var element = document.createElement("a");
        $(element).attr("data-fancybox", "images");
        $(element).attr("href", $(this).attr("src"));
        $(this).wrap(element);
      }
    );
  </script>



  

  
    <!-- MathJax -->
    <script type="text/x-mathjax-config">
      MathJax.Hub.Config({
          tex2jax: {
              inlineMath: [ ['$','$'], ["\\(","\\)"]  ],
              processEscapes: true,
              skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
          }
      });

      MathJax.Hub.Queue(function() {
          var all = MathJax.Hub.getAllJax(), i;
          for(i=0; i < all.length; i += 1) {
              all[i].SourceElement().parentNode.className += ' has-jax';
          }
      });

    </script>

    <script src="https://cdn.staticfile.org/mathjax/2.7.6/MathJax.js?config=TeX-MML-AM_CHTML" ></script>

  





</body>
</html>
